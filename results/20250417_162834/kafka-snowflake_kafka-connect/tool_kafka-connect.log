 Container benchi-kafka-connect  Creating
 Container benchi-kafka-connect  Created
Attaching to benchi-kafka-connect
benchi-kafka-connect  | temurin-jdk                                     808 kB/s | 362 kB     00:00    
benchi-kafka-connect  | Red Hat Universal Base Image 8 (RPMs) - BaseOS  9.7 MB/s | 727 kB     00:00    
benchi-kafka-connect  | Red Hat Universal Base Image 8 (RPMs) - AppStre  31 MB/s | 3.4 MB     00:00    
benchi-kafka-connect  | Red Hat Universal Base Image 8 (RPMs) - CodeRea 3.0 MB/s | 186 kB     00:00    
benchi-kafka-connect  | Package curl-7.61.1-34.el8_10.3.x86_64 is already installed.
benchi-kafka-connect  | Package wget-1.19.5-12.el8_10.x86_64 is already installed.
benchi-kafka-connect  | Dependencies resolved.
benchi-kafka-connect  | ================================================================================
benchi-kafka-connect  |  Package        Arch        Version             Repository                 Size
benchi-kafka-connect  | ================================================================================
benchi-kafka-connect  | Installing:
benchi-kafka-connect  |  jq             x86_64      1.6-9.el8_10        ubi-8-appstream-rpms      203 k
benchi-kafka-connect  | Installing dependencies:
benchi-kafka-connect  |  oniguruma      x86_64      6.8.2-3.el8         ubi-8-appstream-rpms      188 k
benchi-kafka-connect  | 
benchi-kafka-connect  | Transaction Summary
benchi-kafka-connect  | ================================================================================
benchi-kafka-connect  | Install  2 Packages
benchi-kafka-connect  | 
benchi-kafka-connect  | Total download size: 391 k
benchi-kafka-connect  | Installed size: 1.1 M
benchi-kafka-connect  | Downloading Packages:
benchi-kafka-connect  | (1/2): jq-1.6-9.el8_10.x86_64.rpm               6.6 MB/s | 203 kB     00:00    
benchi-kafka-connect  | (2/2): oniguruma-6.8.2-3.el8.x86_64.rpm         5.2 MB/s | 188 kB     00:00    
benchi-kafka-connect  | --------------------------------------------------------------------------------
benchi-kafka-connect  | Total                                           9.9 MB/s | 391 kB     00:00     
benchi-kafka-connect  | Running transaction check
benchi-kafka-connect  | Transaction check succeeded.
benchi-kafka-connect  | Running transaction test
benchi-kafka-connect  | Transaction test succeeded.
benchi-kafka-connect  | Running transaction
benchi-kafka-connect  |   Preparing        :                                                        1/1 
benchi-kafka-connect  |   Installing       : oniguruma-6.8.2-3.el8.x86_64                           1/2 
benchi-kafka-connect  |   Running scriptlet: oniguruma-6.8.2-3.el8.x86_64                           1/2 
benchi-kafka-connect  |   Installing       : jq-1.6-9.el8_10.x86_64                                 2/2 
benchi-kafka-connect  |   Running scriptlet: jq-1.6-9.el8_10.x86_64                                 2/2 
benchi-kafka-connect  |   Verifying        : jq-1.6-9.el8_10.x86_64                                 1/2 
benchi-kafka-connect  |   Verifying        : oniguruma-6.8.2-3.el8.x86_64                           2/2 
benchi-kafka-connect  | 
benchi-kafka-connect  | Installed:
benchi-kafka-connect  |   jq-1.6-9.el8_10.x86_64              oniguruma-6.8.2-3.el8.x86_64             
benchi-kafka-connect  | 
benchi-kafka-connect  | Complete!
benchi-kafka-connect  | Sourcing /benchi/init/init.sh
benchi-kafka-connect  | Running in a "--no-prompt" mode 
benchi-kafka-connect  | Implicit acceptance of the license below:  
benchi-kafka-connect  | Apache License, Version 2.0 
benchi-kafka-connect  | http://www.apache.org/licenses/LICENSE-2.0.txt 
benchi-kafka-connect  | Implicit confirmation of the question: You are about to install 'snowflake-kafka-connector' from Snowflake, Inc., as published on Confluent Hub. 
benchi-kafka-connect  | Downloading component Snowflake Sink Connector 3.1.1, provided by Snowflake, Inc. from Confluent Hub and installing into /usr/share/confluent-hub-components 
benchi-kafka-connect  | Adding installation directory to plugin path in the following files: 
benchi-kafka-connect  |   /etc/kafka/connect-distributed.properties 
benchi-kafka-connect  |   /etc/kafka/connect-standalone.properties 
benchi-kafka-connect  |   /etc/schema-registry/connect-avro-distributed.properties 
benchi-kafka-connect  |   /etc/schema-registry/connect-avro-standalone.properties 
benchi-kafka-connect  |  
benchi-kafka-connect  | Completed 
benchi-kafka-connect  | ===> User
benchi-kafka-connect  | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
benchi-kafka-connect  | ===> Configuring ...
benchi-kafka-connect  | ===> Running preflight checks ... 
benchi-kafka-connect  | ===> Check if Kafka is healthy ...
benchi-kafka-connect  | Using log4j config /etc/cp-base-new/log4j.properties
benchi-kafka-connect  | ===> Launching ... 
benchi-kafka-connect  | ===> Launching kafka-connect ... 
benchi-kafka-connect  | SLF4J: Class path contains multiple SLF4J bindings.
benchi-kafka-connect  | SLF4J: Found binding in [jar:file:/usr/share/java/kafka/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
benchi-kafka-connect  | SLF4J: Found binding in [jar:file:/usr/share/java/kafka-serde-tools/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
benchi-kafka-connect  | SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
benchi-kafka-connect  | SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]
benchi-kafka-connect  | [2025-04-17 16:30:10,677] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli)
benchi-kafka-connect  | [2025-04-17 16:30:10,680] INFO WorkerInfo values: 
benchi-kafka-connect  | 	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/var/log/kafka, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties
benchi-kafka-connect  | 	jvm.spec = Eclipse Adoptium, OpenJDK 64-Bit Server VM, 17.0.13, 17.0.13+11
benchi-kafka-connect  | 	jvm.classpath = /etc/kafka-connect/jars/*:/usr/share/java/kafka/activation-1.1.1.jar:/usr/share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/share/java/kafka/argparse4j-0.7.0.jar:/usr/share/java/kafka/audience-annotations-0.12.0.jar:/usr/share/java/kafka/caffeine-2.9.3.jar:/usr/share/java/kafka/checker-qual-3.19.0.jar:/usr/share/java/kafka/commons-beanutils-1.9.4.jar:/usr/share/java/kafka/commons-cli-1.4.jar:/usr/share/java/kafka/commons-collections-3.2.2.jar:/usr/share/java/kafka/commons-digester-2.1.jar:/usr/share/java/kafka/commons-io-2.16.0.jar:/usr/share/java/kafka/commons-lang3-3.12.0.jar:/usr/share/java/kafka/commons-logging-1.2.jar:/usr/share/java/kafka/commons-validator-1.7.jar:/usr/share/java/kafka/connect-api-7.8.1-ccs.jar:/usr/share/java/kafka/connect-basic-auth-extension-7.8.1-ccs.jar:/usr/share/java/kafka/connect-json-7.8.1-ccs.jar:/usr/share/java/kafka/connect-mirror-7.8.1-ccs.jar:/usr/share/java/kafka/connect-mirror-client-7.8.1-ccs.jar:/usr/share/java/kafka/connect-runtime-7.8.1-ccs.jar:/usr/share/java/kafka/connect-transforms-7.8.1-ccs.jar:/usr/share/java/kafka/error_prone_annotations-2.10.0.jar:/usr/share/java/kafka/hk2-api-2.6.1.jar:/usr/share/java/kafka/hk2-locator-2.6.1.jar:/usr/share/java/kafka/hk2-utils-2.6.1.jar:/usr/share/java/kafka/jackson-annotations-2.16.2.jar:/usr/share/java/kafka/jackson-core-2.16.2.jar:/usr/share/java/kafka/jackson-databind-2.16.2.jar:/usr/share/java/kafka/jackson-dataformat-csv-2.16.2.jar:/usr/share/java/kafka/jackson-datatype-jdk8-2.16.2.jar:/usr/share/java/kafka/jackson-jaxrs-base-2.16.2.jar:/usr/share/java/kafka/jackson-jaxrs-json-provider-2.16.2.jar:/usr/share/java/kafka/jackson-module-afterburner-2.16.2.jar:/usr/share/java/kafka/jackson-module-jaxb-annotations-2.16.2.jar:/usr/share/java/kafka/jackson-module-scala_2.13-2.16.2.jar:/usr/share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/share/java/kafka/jakarta.inject-2.6.1.jar:/usr/share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/share/java/kafka/javassist-3.29.2-GA.jar:/usr/share/java/kafka/javax.activation-api-1.2.0.jar:/usr/share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/share/java/kafka/jaxb-api-2.3.1.jar:/usr/share/java/kafka/jersey-client-2.39.1.jar:/usr/share/java/kafka/jersey-common-2.39.1.jar:/usr/share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/share/java/kafka/jersey-hk2-2.39.1.jar:/usr/share/java/kafka/jersey-server-2.39.1.jar:/usr/share/java/kafka/jetty-client-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-continuation-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-http-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-io-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-security-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-server-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-servlet-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-servlets-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-util-9.4.56.v20240826.jar:/usr/share/java/kafka/jetty-util-ajax-9.4.56.v20240826.jar:/usr/share/java/kafka/jline-3.25.1.jar:/usr/share/java/kafka/jopt-simple-5.0.4.jar:/usr/share/java/kafka/jose4j-0.9.4.jar:/usr/share/java/kafka/jsr305-3.0.2.jar:/usr/share/java/kafka/kafka-clients-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-group-coordinator-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-group-coordinator-api-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-log4j-appender-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-metadata-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-raft-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-server-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-server-common-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-shell-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-storage-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-storage-api-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-streams-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-streams-examples-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-streams-scala_2.13-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-streams-test-utils-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-tools-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-tools-api-7.8.1-ccs.jar:/usr/share/java/kafka/kafka-transaction-coordinator-7.8.1-ccs.jar:/usr/share/java/kafka/kafka.jar:/usr/share/java/kafka/kafka_2.13-7.8.1-ccs.jar:/usr/share/java/kafka/lz4-java-1.8.0.jar:/usr/share/java/kafka/maven-artifact-3.9.6.jar:/usr/share/java/kafka/metrics-core-2.2.0.jar:/usr/share/java/kafka/metrics-core-4.1.12.1.jar:/usr/share/java/kafka/netty-buffer-4.1.115.Final.jar:/usr/share/java/kafka/netty-codec-4.1.115.Final.jar:/usr/share/java/kafka/netty-common-4.1.115.Final.jar:/usr/share/java/kafka/netty-handler-4.1.115.Final.jar:/usr/share/java/kafka/netty-resolver-4.1.115.Final.jar:/usr/share/java/kafka/netty-transport-4.1.115.Final.jar:/usr/share/java/kafka/netty-transport-classes-epoll-4.1.115.Final.jar:/usr/share/java/kafka/netty-transport-native-epoll-4.1.115.Final.jar:/usr/share/java/kafka/netty-transport-native-unix-common-4.1.115.Final.jar:/usr/share/java/kafka/opentelemetry-proto-1.0.0-alpha.jar:/usr/share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/share/java/kafka/paranamer-2.8.jar:/usr/share/java/kafka/pcollections-4.0.1.jar:/usr/share/java/kafka/plexus-utils-3.5.1.jar:/usr/share/java/kafka/protobuf-java-3.25.5.jar:/usr/share/java/kafka/reflections-0.10.2.jar:/usr/share/java/kafka/reload4j-1.2.25.jar:/usr/share/java/kafka/rocksdbjni-7.9.2.jar:/usr/share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/kafka/scala-library-2.13.14.jar:/usr/share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/share/java/kafka/scala-reflect-2.13.14.jar:/usr/share/java/kafka/slf4j-api-1.7.36.jar:/usr/share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/share/java/kafka/snappy-java-1.1.10.5.jar:/usr/share/java/kafka/swagger-annotations-2.2.8.jar:/usr/share/java/kafka/trogdor-7.8.1-ccs.jar:/usr/share/java/kafka/zookeeper-3.8.4.jar:/usr/share/java/kafka/zookeeper-jute-3.8.4.jar:/usr/share/java/kafka/zstd-jni-1.5.6-4.jar:/usr/share/java/confluent-common/build-tools-7.8.1.jar:/usr/share/java/confluent-common/common-config-7.8.1.jar:/usr/share/java/confluent-common/common-metrics-7.8.1.jar:/usr/share/java/confluent-common/common-utils-7.8.1.jar:/usr/share/java/confluent-common/slf4j-api-1.7.36.jar:/usr/share/java/kafka-serde-tools/JSONata4Java-2.4.5.jar:/usr/share/java/kafka-serde-tools/accessors-smart-2.5.0.jar:/usr/share/java/kafka-serde-tools/agrona-1.20.0.jar:/usr/share/java/kafka-serde-tools/animal-sniffer-annotations-1.23.jar:/usr/share/java/kafka-serde-tools/annotations-13.0.jar:/usr/share/java/kafka-serde-tools/annotations-3.0.1.jar:/usr/share/java/kafka-serde-tools/annotations-4.1.1.4.jar:/usr/share/java/kafka-serde-tools/antlr4-runtime-4.13.1.jar:/usr/share/java/kafka-serde-tools/api-common-2.18.0.jar:/usr/share/java/kafka-serde-tools/argparse4j-0.7.0.jar:/usr/share/java/kafka-serde-tools/asm-9.3.jar:/usr/share/java/kafka-serde-tools/auto-service-annotations-1.1.1.jar:/usr/share/java/kafka-serde-tools/auto-value-annotations-1.10.4.jar:/usr/share/java/kafka-serde-tools/avro-1.11.4.jar:/usr/share/java/kafka-serde-tools/aws-java-sdk-core-1.12.701.jar:/usr/share/java/kafka-serde-tools/aws-java-sdk-kms-1.12.701.jar:/usr/share/java/kafka-serde-tools/azure-core-1.49.1.jar:/usr/share/java/kafka-serde-tools/azure-core-http-netty-1.15.1.jar:/usr/share/java/kafka-serde-tools/azure-identity-1.13.0.jar:/usr/share/java/kafka-serde-tools/azure-json-1.1.0.jar:/usr/share/java/kafka-serde-tools/azure-security-keyvault-keys-4.8.5.jar:/usr/share/java/kafka-serde-tools/azure-xml-1.0.0.jar:/usr/share/java/kafka-serde-tools/caffeine-2.9.3.jar:/usr/share/java/kafka-serde-tools/cel-core-0.4.4.jar:/usr/share/java/kafka-serde-tools/cel-generated-antlr-0.4.4.jar:/usr/share/java/kafka-serde-tools/cel-generated-pb-0.4.4.jar:/usr/share/java/kafka-serde-tools/cel-jackson-0.4.4.jar:/usr/share/java/kafka-serde-tools/cel-tools-0.4.4.jar:/usr/share/java/kafka-serde-tools/checker-qual-3.33.0.jar:/usr/share/java/kafka-serde-tools/classgraph-4.8.138.jar:/usr/share/java/kafka-serde-tools/commons-beanutils-1.9.4.jar:/usr/share/java/kafka-serde-tools/commons-codec-1.16.1.jar:/usr/share/java/kafka-serde-tools/commons-collections-3.2.2.jar:/usr/share/java/kafka-serde-tools/commons-compress-1.26.1.jar:/usr/share/java/kafka-serde-tools/commons-digester-2.1.jar:/usr/share/java/kafka-serde-tools/commons-io-2.16.0.jar:/usr/share/java/kafka-serde-tools/commons-lang3-3.12.0.jar:/usr/share/java/kafka-serde-tools/commons-logging-1.2.jar:/usr/share/java/kafka-serde-tools/commons-text-1.10.0.jar:/usr/share/java/kafka-serde-tools/commons-validator-1.7.jar:/usr/share/java/kafka-serde-tools/conscrypt-openjdk-uber-2.5.2.jar:/usr/share/java/kafka-serde-tools/content-type-2.3.jar:/usr/share/java/kafka-serde-tools/dek-registry-client-7.8.1.jar:/usr/share/java/kafka-serde-tools/error_prone_annotations-2.18.0.jar:/usr/share/java/kafka-serde-tools/everit-json-schema-1.14.3.jar:/usr/share/java/kafka-serde-tools/failureaccess-1.0.1.jar:/usr/share/java/kafka-serde-tools/gax-2.35.0.jar:/usr/share/java/kafka-serde-tools/gax-grpc-2.35.0.jar:/usr/share/java/kafka-serde-tools/gax-httpjson-2.35.0.jar:/usr/share/java/kafka-serde-tools/google-api-client-1.35.2.jar:/usr/share/java/kafka-serde-tools/google-api-services-cloudkms-v1-rev20221107-2.0.0.jar:/usr/share/java/kafka-serde-tools/google-auth-library-credentials-1.19.0.jar:/usr/share/java/kafka-serde-tools/google-auth-library-oauth2-http-1.20.0.jar:/usr/share/java/kafka-serde-tools/google-cloud-kms-2.31.0.jar:/usr/share/java/kafka-serde-tools/google-http-client-1.43.3.jar:/usr/share/java/kafka-serde-tools/google-http-client-apache-v2-1.42.0.jar:/usr/share/java/kafka-serde-tools/google-http-client-gson-1.43.3.jar:/usr/share/java/kafka-serde-tools/google-oauth-client-1.34.1.jar:/usr/share/java/kafka-serde-tools/grpc-alts-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-api-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-auth-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-context-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-core-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-google-common-protos-2.26.0.jar:/usr/share/java/kafka-serde-tools/grpc-google-iam-v1-1.21.0.jar:/usr/share/java/kafka-serde-tools/grpc-googleapis-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-grpclb-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-inprocess-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-netty-shaded-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-protobuf-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-protobuf-lite-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-services-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-stub-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-util-1.58.0.jar:/usr/share/java/kafka-serde-tools/grpc-xds-1.58.0.jar:/usr/share/java/kafka-serde-tools/gson-2.9.0.jar:/usr/share/java/kafka-serde-tools/guava-32.0.1-jre.jar:/usr/share/java/kafka-serde-tools/handy-uri-templates-2.1.8.jar:/usr/share/java/kafka-serde-tools/httpclient-4.5.13.jar:/usr/share/java/kafka-serde-tools/httpcore-4.4.15.jar:/usr/share/java/kafka-serde-tools/j2objc-annotations-2.8.jar:/usr/share/java/kafka-serde-tools/jackson-annotations-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-core-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-databind-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-cbor-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-csv-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-protobuf-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-xml-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-yaml-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-guava-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-jdk8-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-joda-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-jsr310-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-protobuf-0.9.13.jar:/usr/share/java/kafka-serde-tools/jackson-jaxrs-base-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-jaxrs-json-provider-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-module-jaxb-annotations-2.16.0.jar:/usr/share/java/kafka-serde-tools/jackson-module-parameter-names-2.16.0.jar:/usr/share/java/kafka-serde-tools/jakarta.activation-api-1.2.2.jar:/usr/share/java/kafka-serde-tools/jakarta.xml.bind-api-2.3.3.jar:/usr/share/java/kafka-serde-tools/javapoet-1.13.0.jar:/usr/share/java/kafka-serde-tools/javax.annotation-api-1.3.2.jar:/usr/share/java/kafka-serde-tools/jcip-annotations-1.0-1.jar:/usr/share/java/kafka-serde-tools/jmespath-java-1.12.701.jar:/usr/share/java/kafka-serde-tools/jna-5.13.0.jar:/usr/share/java/kafka-serde-tools/jna-platform-5.6.0.jar:/usr/share/java/kafka-serde-tools/joda-time-2.10.14.jar:/usr/share/java/kafka-serde-tools/jopt-simple-5.0.4.jar:/usr/share/java/kafka-serde-tools/jose4j-0.9.5.jar:/usr/share/java/kafka-serde-tools/json-20231013.jar:/usr/share/java/kafka-serde-tools/json-sKema-0.18.0.jar:/usr/share/java/kafka-serde-tools/json-smart-2.5.0.jar:/usr/share/java/kafka-serde-tools/jsr305-3.0.2.jar:/usr/share/java/kafka-serde-tools/kafka-avro-serializer-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-converter-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-data-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-connect-json-schema-converter-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-connect-protobuf-converter-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-schema-provider-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-schema-serializer-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-serializer-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-log4j-appender-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-provider-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-serializer-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-types-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-converter-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-aws-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-azure-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-gcp-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-hcvault-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-tink-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-rules-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-serializer-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-server-common-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-storage-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-storage-api-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-streams-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-streams-avro-serde-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-json-schema-serde-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-protobuf-serde-7.8.1.jar:/usr/share/java/kafka-serde-tools/kafka-tools-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kafka-tools-api-7.8.1-ccs.jar:/usr/share/java/kafka-serde-tools/kotlin-reflect-2.0.0.jar:/usr/share/java/kafka-serde-tools/kotlin-script-runtime-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-common-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-compiler-embeddable-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-compiler-impl-embeddable-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-jvm-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-1.9.10.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-common-1.8.0.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-jdk7-1.8.0.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-jdk8-1.8.0.jar:/usr/share/java/kafka-serde-tools/kotlinpoet-jvm-1.18.0.jar:/usr/share/java/kafka-serde-tools/lang-tag-1.7.jar:/usr/share/java/kafka-serde-tools/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/share/java/kafka-serde-tools/logredactor-1.0.12.jar:/usr/share/java/kafka-serde-tools/logredactor-metrics-1.0.12.jar:/usr/share/java/kafka-serde-tools/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/usr/share/java/kafka-serde-tools/metrics-core-2.2.0.jar:/usr/share/java/kafka-serde-tools/minimal-json-0.9.5.jar:/usr/share/java/kafka-serde-tools/msal4j-1.15.1.jar:/usr/share/java/kafka-serde-tools/msal4j-persistence-extension-1.3.0.jar:/usr/share/java/kafka-serde-tools/netty-buffer-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-dns-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-http-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-http2-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-socks-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-common-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-handler-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-handler-proxy-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-resolver-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-classes-macos-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-native-macos-4.1.113.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final-linux-aarch_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final-linux-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final-osx-aarch_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final-windows-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.66.Final.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-classes-2.0.66.Final.jar:/usr/share/java/kafka-serde-tools/netty-transport-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-transport-classes-epoll-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-transport-classes-kqueue-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-epoll-4.1.113.Final-linux-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-kqueue-4.1.113.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-unix-common-4.1.113.Final.jar:/usr/share/java/kafka-serde-tools/nimbus-jose-jwt-9.37.3.jar:/usr/share/java/kafka-serde-tools/oauth2-oidc-sdk-11.9.1.jar:/usr/share/java/kafka-serde-tools/okio-jvm-3.4.0.jar:/usr/share/java/kafka-serde-tools/opencensus-api-0.31.1.jar:/usr/share/java/kafka-serde-tools/opencensus-contrib-http-util-0.31.1.jar:/usr/share/java/kafka-serde-tools/opencensus-proto-0.2.0.jar:/usr/share/java/kafka-serde-tools/pcollections-4.0.1.jar:/usr/share/java/kafka-serde-tools/perfmark-api-0.26.0.jar:/usr/share/java/kafka-serde-tools/picocli-4.7.5.jar:/usr/share/java/kafka-serde-tools/proto-google-cloud-kms-v1-0.124.0.jar:/usr/share/java/kafka-serde-tools/proto-google-common-protos-2.22.1.jar:/usr/share/java/kafka-serde-tools/proto-google-iam-v1-1.21.0.jar:/usr/share/java/kafka-serde-tools/protobuf-java-3.25.5.jar:/usr/share/java/kafka-serde-tools/protobuf-java-util-3.25.5.jar:/usr/share/java/kafka-serde-tools/protoparser-4.0.3.jar:/usr/share/java/kafka-serde-tools/re2j-1.6.jar:/usr/share/java/kafka-serde-tools/reactive-streams-1.0.4.jar:/usr/share/java/kafka-serde-tools/reactor-core-3.4.38.jar:/usr/share/java/kafka-serde-tools/reactor-netty-core-1.0.45.jar:/usr/share/java/kafka-serde-tools/reactor-netty-http-1.0.45.jar:/usr/share/java/kafka-serde-tools/reload4j-1.2.25.jar:/usr/share/java/kafka-serde-tools/rocksdbjni-7.9.2.jar:/usr/share/java/kafka-serde-tools/scala-library-2.13.11.jar:/usr/share/java/kafka-serde-tools/slf4j-api-1.7.36.jar:/usr/share/java/kafka-serde-tools/slf4j-reload4j-1.7.36.jar:/usr/share/java/kafka-serde-tools/snakeyaml-2.0.jar:/usr/share/java/kafka-serde-tools/stax2-api-4.2.1.jar:/usr/share/java/kafka-serde-tools/swagger-annotations-2.1.10.jar:/usr/share/java/kafka-serde-tools/threetenbp-1.6.8.jar:/usr/share/java/kafka-serde-tools/tink-1.14.1.jar:/usr/share/java/kafka-serde-tools/tink-awskms-1.10.1.jar:/usr/share/java/kafka-serde-tools/tink-gcpkms-1.10.0.jar:/usr/share/java/kafka-serde-tools/validation-api-2.0.1.Final.jar:/usr/share/java/kafka-serde-tools/vault-java-driver-5.4.0.jar:/usr/share/java/kafka-serde-tools/wire-runtime-jvm-5.0.0.jar:/usr/share/java/kafka-serde-tools/wire-schema-jvm-5.0.0.jar:/usr/share/java/kafka-serde-tools/woodstox-core-6.5.1.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.8.1.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/audience-annotations-0.12.0.jar:/usr/bin/../share/java/kafka/caffeine-2.9.3.jar:/usr/bin/../share/java/kafka/checker-qual-3.19.0.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.9.4.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.2.jar:/usr/bin/../share/java/kafka/commons-digester-2.1.jar:/usr/bin/../share/java/kafka/commons-io-2.16.0.jar:/usr/bin/../share/java/kafka/commons-lang3-3.12.0.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/commons-validator-1.7.jar:/usr/bin/../share/java/kafka/connect-api-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-runtime-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/error_prone_annotations-2.10.0.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-core-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-databind-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-module-afterburner-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.16.2.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.56.v20240826.jar:/usr/bin/../share/java/kafka/jline-3.25.1.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jose4j-0.9.4.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/kafka-clients-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-api-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-server-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-shell-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-tools-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-transaction-coordinator-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/maven-artifact-3.9.6.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-common-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.115.Final.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.115.Final.jar:/usr/bin/../share/java/kafka/opentelemetry-proto-1.0.0-alpha.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/pcollections-4.0.1.jar:/usr/bin/../share/java/kafka/plexus-utils-3.5.1.jar:/usr/bin/../share/java/kafka/protobuf-java-3.25.5.jar:/usr/bin/../share/java/kafka/reflections-0.10.2.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.9.2.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/scala-library-2.13.14.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.14.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.5.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/trogdor-7.8.1-ccs.jar:/usr/bin/../share/java/kafka/zookeeper-3.8.4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.8.4.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.6-4.jar:/usr/bin/../share/java/confluent-telemetry/confluent-metrics-7.8.1-ce.jar
benchi-kafka-connect  | 	os.spec = Linux, amd64, 6.1.132-147.221.amzn2023.x86_64
benchi-kafka-connect  | 	os.vcpus = 8
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.WorkerInfo)
benchi-kafka-connect  | [2025-04-17 16:30:10,681] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli)
benchi-kafka-connect  | [2025-04-17 16:30:10,750] INFO Loading plugin from: /usr/share/java/cp-base-new (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:10,979] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cp-base-new/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:10,980] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,155] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,156] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,167] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,167] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,506] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,506] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,519] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,519] INFO Loading plugin from: /usr/share/java/confluent-telemetry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,525] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-telemetry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,525] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,549] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,549] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,555] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,555] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,579] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,579] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,647] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,647] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,796] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,797] INFO Loading plugin from: /usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:11,838] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,062] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,068] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@4567f35d (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,068] INFO Scanning plugins with ServiceLoaderScanner took 1319 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,070] INFO Loading plugin from: /usr/share/java/cp-base-new (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,981] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cp-base-new/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:12,981] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:20,226] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:20,226] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:20,230] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:20,230] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:22,467] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:22,467] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:22,590] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:22,590] INFO Loading plugin from: /usr/share/java/confluent-telemetry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:23,236] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-telemetry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:23,236] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:24,515] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:24,515] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:24,764] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:24,764] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:25,246] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:25,247] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:26,010] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:26,010] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:26,614] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:26,614] INFO Loading plugin from: /usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:29,633] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:29,634] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:31,617] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@4567f35d (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:31,617] INFO Scanning plugins with ReflectionScanner took 19547 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner)
benchi-kafka-connect  | [2025-04-17 16:30:31,623] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
benchi-kafka-connect  | file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/	com.snowflake.kafka.connector.SnowflakeSinkConnector	sink	3.1.1
benchi-kafka-connect  | file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/	com.snowflake.kafka.connector.records.SnowflakeAvroConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/	com.snowflake.kafka.connector.records.SnowflakeAvroConverterWithoutSchemaRegistry	converter	undefined
benchi-kafka-connect  | file:/usr/share/confluent-hub-components/snowflakeinc-snowflake-kafka-connector/	com.snowflake.kafka.connector.records.SnowflakeJsonConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/acl/	io.confluent.connect.avro.AvroConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/confluent-control-center/	io.confluent.connect.avro.AvroConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.avro.AvroConverter	converter	undefined
benchi-kafka-connect  | classpath	io.confluent.connect.avro.AvroConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/acl/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/confluent-control-center/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
benchi-kafka-connect  | classpath	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/acl/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/confluent-control-center/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
benchi-kafka-connect  | file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
benchi-kafka-connect  | classpath	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
benchi-kafka-connect  | ]
benchi-kafka-connect  | Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,624] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'com.snowflake.kafka.connector.records.SnowflakeAvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'com.snowflake.kafka.connector.SnowflakeSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'com.snowflake.kafka.connector.records.SnowflakeAvroConverterWithoutSchemaRegistry' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'com.snowflake.kafka.connector.records.SnowflakeJsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,625] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'JsonSchema' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'SnowflakeSink' to plugin 'com.snowflake.kafka.connector.SnowflakeSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'SnowflakeSinkConnector' to plugin 'com.snowflake.kafka.connector.SnowflakeSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'AvroConverter' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'SchemaRegistryConfigProvider' to plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,628] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'SnowflakeJsonConverter' to plugin 'com.snowflake.kafka.connector.records.SnowflakeJsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Protobuf' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'SnowflakeAvroConverter' to plugin 'com.snowflake.kafka.connector.records.SnowflakeAvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'ConnectSecurityExtension' to plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'SnowflakeAvroConverterWithoutSchemaRegistry' to plugin 'com.snowflake.kafka.connector.records.SnowflakeAvroConverterWithoutSchemaRegistry' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'ByteArrayConverter' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'ProtobufConverter' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,629] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'SnowflakeJson' to plugin 'com.snowflake.kafka.connector.records.SnowflakeJsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'JsonSchemaConverter' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,630] INFO Added alias 'SchemaRegistry' to plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
benchi-kafka-connect  | [2025-04-17 16:30:31,652] INFO DistributedConfig values: 
benchi-kafka-connect  | 	access.control.allow.methods = 
benchi-kafka-connect  | 	access.control.allow.origin = 
benchi-kafka-connect  | 	admin.listeners = null
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = 
benchi-kafka-connect  | 	config.providers = []
benchi-kafka-connect  | 	config.storage.replication.factor = 1
benchi-kafka-connect  | 	config.storage.topic = benchi-connect-configs
benchi-kafka-connect  | 	connect.protocol = sessioned
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	connector.client.config.override.policy = All
benchi-kafka-connect  | 	exactly.once.source.support = disabled
benchi-kafka-connect  | 	group.id = connect-cluster-group
benchi-kafka-connect  | 	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
benchi-kafka-connect  | 	heartbeat.interval.ms = 3000
benchi-kafka-connect  | 	inter.worker.key.generation.algorithm = HmacSHA256
benchi-kafka-connect  | 	inter.worker.key.size = null
benchi-kafka-connect  | 	inter.worker.key.ttl.ms = 3600000
benchi-kafka-connect  | 	inter.worker.signature.algorithm = HmacSHA256
benchi-kafka-connect  | 	inter.worker.verification.algorithms = [HmacSHA256]
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  | 	listeners = [http://:8083]
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	offset.flush.interval.ms = 10000
benchi-kafka-connect  | 	offset.flush.timeout.ms = 5000
benchi-kafka-connect  | 	offset.storage.partitions = 25
benchi-kafka-connect  | 	offset.storage.replication.factor = 1
benchi-kafka-connect  | 	offset.storage.topic = benchi-connect-offsets
benchi-kafka-connect  | 	plugin.discovery = hybrid_warn
benchi-kafka-connect  | 	plugin.path = [/usr/share/java, /usr/share/confluent-hub-components]
benchi-kafka-connect  | 	rebalance.timeout.ms = 60000
benchi-kafka-connect  | 	receive.buffer.bytes = 32768
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 40000
benchi-kafka-connect  | 	response.http.headers.config = 
benchi-kafka-connect  | 	rest.advertised.host.name = benchi-kafka-connect
benchi-kafka-connect  | 	rest.advertised.listener = null
benchi-kafka-connect  | 	rest.advertised.port = null
benchi-kafka-connect  | 	rest.extension.classes = []
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	scheduled.rebalance.max.delay.ms = 300000
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	session.timeout.ms = 10000
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.client.auth = none
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	status.storage.partitions = 5
benchi-kafka-connect  | 	status.storage.replication.factor = 1
benchi-kafka-connect  | 	status.storage.topic = benchi-connect-status
benchi-kafka-connect  | 	task.shutdown.graceful.timeout.ms = 5000
benchi-kafka-connect  | 	topic.creation.enable = true
benchi-kafka-connect  | 	topic.tracking.allow.reset = true
benchi-kafka-connect  | 	topic.tracking.enable = true
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  | 	worker.sync.timeout.ms = 3000
benchi-kafka-connect  | 	worker.unsync.backoff.ms = 300000
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.distributed.DistributedConfig)
benchi-kafka-connect  | [2025-04-17 16:30:31,653] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:31,655] INFO AdminClientConfig values: 
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	bootstrap.controllers = []
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = 
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retries = 2147483647
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  |  (org.apache.kafka.clients.admin.AdminClientConfig)
benchi-kafka-connect  | [2025-04-17 16:30:31,715] INFO These configurations '[log4j.loggers, config.storage.topic, auto.create.topics.enable, rest.advertised.host.name, group.id, status.storage.topic, plugin.path, offset.flush.interval.ms, rest.port, config.storage.replication.factor, status.storage.replication.factor, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
benchi-kafka-connect  | [2025-04-17 16:30:31,715] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:31,715] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:31,715] INFO Kafka startTimeMs: 1744907431715 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,004] INFO Kafka cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.connect.runtime.WorkerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,005] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,010] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
benchi-kafka-connect  | [2025-04-17 16:30:32,010] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
benchi-kafka-connect  | [2025-04-17 16:30:32,010] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
benchi-kafka-connect  | [2025-04-17 16:30:32,015] INFO PublicConfig values: 
benchi-kafka-connect  | 	access.control.allow.methods = 
benchi-kafka-connect  | 	access.control.allow.origin = 
benchi-kafka-connect  | 	admin.listeners = null
benchi-kafka-connect  | 	listeners = [http://:8083]
benchi-kafka-connect  | 	response.http.headers.config = 
benchi-kafka-connect  | 	rest.advertised.host.name = benchi-kafka-connect
benchi-kafka-connect  | 	rest.advertised.listener = null
benchi-kafka-connect  | 	rest.advertised.port = null
benchi-kafka-connect  | 	rest.extension.classes = []
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.client.auth = none
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	topic.tracking.allow.reset = true
benchi-kafka-connect  | 	topic.tracking.enable = true
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,021] INFO Logging initialized @21887ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
benchi-kafka-connect  | [2025-04-17 16:30:32,050] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,051] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,069] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 17.0.13+11 (org.eclipse.jetty.server.Server)
benchi-kafka-connect  | [2025-04-17 16:30:32,092] INFO Started http_8083@192afa8e{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector)
benchi-kafka-connect  | [2025-04-17 16:30:32,093] INFO Started @21958ms (org.eclipse.jetty.server.Server)
benchi-kafka-connect  | [2025-04-17 16:30:32,107] INFO Advertised URI: http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,107] INFO REST server listening at http://172.25.0.3:8083/, advertising URL http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,108] INFO Advertised URI: http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,108] INFO REST admin endpoints at http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,108] INFO Advertised URI: http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,108] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy)
benchi-kafka-connect  | [2025-04-17 16:30:32,113] INFO JsonConverterConfig values: 
benchi-kafka-connect  | 	converter.type = key
benchi-kafka-connect  | 	decimal.format = BASE64
benchi-kafka-connect  | 	replace.null.with.default = true
benchi-kafka-connect  | 	schemas.cache.size = 1000
benchi-kafka-connect  | 	schemas.enable = false
benchi-kafka-connect  |  (org.apache.kafka.connect.json.JsonConverterConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,127] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,127] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,127] INFO Kafka startTimeMs: 1744907432127 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,133] INFO JsonConverterConfig values: 
benchi-kafka-connect  | 	converter.type = key
benchi-kafka-connect  | 	decimal.format = BASE64
benchi-kafka-connect  | 	replace.null.with.default = true
benchi-kafka-connect  | 	schemas.cache.size = 1000
benchi-kafka-connect  | 	schemas.enable = false
benchi-kafka-connect  |  (org.apache.kafka.connect.json.JsonConverterConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,133] INFO JsonConverterConfig values: 
benchi-kafka-connect  | 	converter.type = value
benchi-kafka-connect  | 	decimal.format = BASE64
benchi-kafka-connect  | 	replace.null.with.default = true
benchi-kafka-connect  | 	schemas.cache.size = 1000
benchi-kafka-connect  | 	schemas.enable = false
benchi-kafka-connect  |  (org.apache.kafka.connect.json.JsonConverterConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,148] INFO Advertised URI: http://benchi-kafka-connect:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,172] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,172] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,172] INFO Kafka startTimeMs: 1744907432172 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,174] INFO Kafka Connect worker initialization took 21497ms (org.apache.kafka.connect.cli.AbstractConnectCli)
benchi-kafka-connect  | [2025-04-17 16:30:32,174] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect)
benchi-kafka-connect  | [2025-04-17 16:30:32,176] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,176] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:32,178] INFO Worker starting (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:32,178] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
benchi-kafka-connect  | [2025-04-17 16:30:32,178] INFO Starting KafkaBasedLog with topic benchi-connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,178] INFO AdminClientConfig values: 
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	bootstrap.controllers = []
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-shared-admin
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retries = 2147483647
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  |  (org.apache.kafka.clients.admin.AdminClientConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,182] INFO These configurations '[log4j.loggers, config.storage.topic, auto.create.topics.enable, metrics.context.connect.group.id, rest.advertised.host.name, group.id, status.storage.topic, plugin.path, offset.flush.interval.ms, rest.port, config.storage.replication.factor, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,182] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,182] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,182] INFO Kafka startTimeMs: 1744907432182 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,203] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,233] INFO Created topic (name=benchi-connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at benchi-kafka:9092 (org.apache.kafka.connect.util.TopicAdmin)
benchi-kafka-connect  | [2025-04-17 16:30:32,233] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
benchi-kafka-connect  | [2025-04-17 16:30:32,233] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
benchi-kafka-connect  | [2025-04-17 16:30:32,234] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
benchi-kafka-connect  | [2025-04-17 16:30:32,240] INFO ProducerConfig values: 
benchi-kafka-connect  | 	acks = -1
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	batch.size = 16384
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	buffer.memory = 33554432
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-offsets
benchi-kafka-connect  | 	compression.gzip.level = -1
benchi-kafka-connect  | 	compression.lz4.level = 9
benchi-kafka-connect  | 	compression.type = none
benchi-kafka-connect  | 	compression.zstd.level = 3
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	delivery.timeout.ms = 2147483647
benchi-kafka-connect  | 	enable.idempotence = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
benchi-kafka-connect  | 	linger.ms = 0
benchi-kafka-connect  | 	max.block.ms = 60000
benchi-kafka-connect  | 	max.in.flight.requests.per.connection = 1
benchi-kafka-connect  | 	max.request.size = 1048576
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.max.idle.ms = 300000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partitioner.adaptive.partitioning.enable = true
benchi-kafka-connect  | 	partitioner.availability.timeout.ms = 0
benchi-kafka-connect  | 	partitioner.class = null
benchi-kafka-connect  | 	partitioner.ignore.keys = false
benchi-kafka-connect  | 	receive.buffer.bytes = 32768
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retries = 2147483647
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	transaction.timeout.ms = 60000
benchi-kafka-connect  | 	transactional.id = null
benchi-kafka-connect  | 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
benchi-kafka-connect  |  (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,260] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,280] INFO These configurations '[log4j.loggers, auto.create.topics.enable, group.id, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,280] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,280] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,281] INFO Kafka startTimeMs: 1744907432280 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,285] INFO ConsumerConfig values: 
benchi-kafka-connect  | 	allow.auto.create.topics = true
benchi-kafka-connect  | 	auto.commit.interval.ms = 5000
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	auto.offset.reset = earliest
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	check.crcs = true
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-offsets
benchi-kafka-connect  | 	client.rack = 
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.auto.commit = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	exclude.internal.topics = true
benchi-kafka-connect  | 	fetch.max.bytes = 52428800
benchi-kafka-connect  | 	fetch.max.wait.ms = 500
benchi-kafka-connect  | 	fetch.min.bytes = 1
benchi-kafka-connect  | 	group.id = connect-cluster-group
benchi-kafka-connect  | 	group.instance.id = null
benchi-kafka-connect  | 	group.protocol = classic
benchi-kafka-connect  | 	group.remote.assignor = null
benchi-kafka-connect  | 	heartbeat.interval.ms = 3000
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	internal.leave.group.on.close = true
benchi-kafka-connect  | 	internal.throw.on.fetch.stable.offset.unsupported = false
benchi-kafka-connect  | 	isolation.level = read_uncommitted
benchi-kafka-connect  | 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  | 	max.partition.fetch.bytes = 1048576
benchi-kafka-connect  | 	max.poll.interval.ms = 300000
benchi-kafka-connect  | 	max.poll.records = 500
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	session.timeout.ms = 45000
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  |  (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,290] INFO [Producer clientId=connect-cluster-group-offsets] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,296] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,324] INFO These configurations '[log4j.loggers, auto.create.topics.enable, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,325] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,325] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,325] INFO Kafka startTimeMs: 1744907432325 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,333] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,346] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Assigned to partition(s): benchi-connect-offsets-17, benchi-connect-offsets-20, benchi-connect-offsets-11, benchi-connect-offsets-23, benchi-connect-offsets-14, benchi-connect-offsets-5, benchi-connect-offsets-0, benchi-connect-offsets-8, benchi-connect-offsets-7, benchi-connect-offsets-4, benchi-connect-offsets-1, benchi-connect-offsets-10, benchi-connect-offsets-13, benchi-connect-offsets-24, benchi-connect-offsets-21, benchi-connect-offsets-16, benchi-connect-offsets-3, benchi-connect-offsets-9, benchi-connect-offsets-15, benchi-connect-offsets-18, benchi-connect-offsets-19, benchi-connect-offsets-22, benchi-connect-offsets-6, benchi-connect-offsets-2, benchi-connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
benchi-kafka-connect  | [2025-04-17 16:30:32,348] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,348] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,349] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,350] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,350] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,350] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,350] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,481] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,481] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,481] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,481] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,482] INFO [Consumer clientId=connect-cluster-group-offsets, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,484] INFO Finished reading KafkaBasedLog for topic benchi-connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,484] INFO Started KafkaBasedLog for topic benchi-connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,484] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
benchi-kafka-connect  | [2025-04-17 16:30:32,485] INFO Worker started (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:32,485] INFO Starting KafkaBasedLog with topic benchi-connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,524] INFO Created topic (name=benchi-connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at benchi-kafka:9092 (org.apache.kafka.connect.util.TopicAdmin)
benchi-kafka-connect  | [2025-04-17 16:30:32,525] INFO ProducerConfig values: 
benchi-kafka-connect  | 	acks = -1
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	batch.size = 16384
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	buffer.memory = 33554432
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-statuses
benchi-kafka-connect  | 	compression.gzip.level = -1
benchi-kafka-connect  | 	compression.lz4.level = 9
benchi-kafka-connect  | 	compression.type = none
benchi-kafka-connect  | 	compression.zstd.level = 3
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	delivery.timeout.ms = 120000
benchi-kafka-connect  | 	enable.idempotence = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
benchi-kafka-connect  | 	linger.ms = 0
benchi-kafka-connect  | 	max.block.ms = 60000
benchi-kafka-connect  | 	max.in.flight.requests.per.connection = 1
benchi-kafka-connect  | 	max.request.size = 1048576
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.max.idle.ms = 300000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partitioner.adaptive.partitioning.enable = true
benchi-kafka-connect  | 	partitioner.availability.timeout.ms = 0
benchi-kafka-connect  | 	partitioner.class = null
benchi-kafka-connect  | 	partitioner.ignore.keys = false
benchi-kafka-connect  | 	receive.buffer.bytes = 32768
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retries = 0
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	transaction.timeout.ms = 60000
benchi-kafka-connect  | 	transactional.id = null
benchi-kafka-connect  | 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
benchi-kafka-connect  |  (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,526] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,530] INFO These configurations '[log4j.loggers, auto.create.topics.enable, group.id, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,531] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,531] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,531] INFO Kafka startTimeMs: 1744907432531 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,534] INFO ConsumerConfig values: 
benchi-kafka-connect  | 	allow.auto.create.topics = true
benchi-kafka-connect  | 	auto.commit.interval.ms = 5000
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	auto.offset.reset = earliest
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	check.crcs = true
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-statuses
benchi-kafka-connect  | 	client.rack = 
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.auto.commit = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	exclude.internal.topics = true
benchi-kafka-connect  | 	fetch.max.bytes = 52428800
benchi-kafka-connect  | 	fetch.max.wait.ms = 500
benchi-kafka-connect  | 	fetch.min.bytes = 1
benchi-kafka-connect  | 	group.id = connect-cluster-group
benchi-kafka-connect  | 	group.instance.id = null
benchi-kafka-connect  | 	group.protocol = classic
benchi-kafka-connect  | 	group.remote.assignor = null
benchi-kafka-connect  | 	heartbeat.interval.ms = 3000
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	internal.leave.group.on.close = true
benchi-kafka-connect  | 	internal.throw.on.fetch.stable.offset.unsupported = false
benchi-kafka-connect  | 	isolation.level = read_uncommitted
benchi-kafka-connect  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
benchi-kafka-connect  | 	max.partition.fetch.bytes = 1048576
benchi-kafka-connect  | 	max.poll.interval.ms = 300000
benchi-kafka-connect  | 	max.poll.records = 500
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	session.timeout.ms = 45000
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  |  (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,534] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,537] INFO These configurations '[log4j.loggers, auto.create.topics.enable, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,538] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,539] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,539] INFO Kafka startTimeMs: 1744907432538 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,540] INFO [Producer clientId=connect-cluster-group-statuses] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,547] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,550] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Assigned to partition(s): benchi-connect-status-1, benchi-connect-status-3, benchi-connect-status-2, benchi-connect-status-0, benchi-connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
benchi-kafka-connect  | [2025-04-17 16:30:32,550] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,551] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,551] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,551] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,551] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,593] INFO Started o.e.j.s.ServletContextHandler@75ced253{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
benchi-kafka-connect  | [2025-04-17 16:30:32,593] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:32,593] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
benchi-kafka-connect  | [2025-04-17 16:30:32,691] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,691] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,691] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,691] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,691] INFO [Consumer clientId=connect-cluster-group-statuses, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,692] INFO Finished reading KafkaBasedLog for topic benchi-connect-status (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,692] INFO Started KafkaBasedLog for topic benchi-connect-status (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,694] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
benchi-kafka-connect  | [2025-04-17 16:30:32,695] INFO Starting KafkaBasedLog with topic benchi-connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,727] INFO Created topic (name=benchi-connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at benchi-kafka:9092 (org.apache.kafka.connect.util.TopicAdmin)
benchi-kafka-connect  | [2025-04-17 16:30:32,728] INFO ProducerConfig values: 
benchi-kafka-connect  | 	acks = -1
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	batch.size = 16384
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	buffer.memory = 33554432
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-configs
benchi-kafka-connect  | 	compression.gzip.level = -1
benchi-kafka-connect  | 	compression.lz4.level = 9
benchi-kafka-connect  | 	compression.type = none
benchi-kafka-connect  | 	compression.zstd.level = 3
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	delivery.timeout.ms = 2147483647
benchi-kafka-connect  | 	enable.idempotence = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
benchi-kafka-connect  | 	linger.ms = 0
benchi-kafka-connect  | 	max.block.ms = 60000
benchi-kafka-connect  | 	max.in.flight.requests.per.connection = 1
benchi-kafka-connect  | 	max.request.size = 1048576
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.max.idle.ms = 300000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partitioner.adaptive.partitioning.enable = true
benchi-kafka-connect  | 	partitioner.availability.timeout.ms = 0
benchi-kafka-connect  | 	partitioner.class = null
benchi-kafka-connect  | 	partitioner.ignore.keys = false
benchi-kafka-connect  | 	receive.buffer.bytes = 32768
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retries = 2147483647
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	transaction.timeout.ms = 60000
benchi-kafka-connect  | 	transactional.id = null
benchi-kafka-connect  | 	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
benchi-kafka-connect  |  (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,728] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,732] INFO These configurations '[log4j.loggers, auto.create.topics.enable, group.id, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,732] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,732] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,732] INFO Kafka startTimeMs: 1744907432732 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,733] INFO ConsumerConfig values: 
benchi-kafka-connect  | 	allow.auto.create.topics = true
benchi-kafka-connect  | 	auto.commit.interval.ms = 5000
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	auto.offset.reset = earliest
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	check.crcs = true
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connect-cluster-group-configs
benchi-kafka-connect  | 	client.rack = 
benchi-kafka-connect  | 	connections.max.idle.ms = 180000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.auto.commit = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	exclude.internal.topics = true
benchi-kafka-connect  | 	fetch.max.bytes = 52428800
benchi-kafka-connect  | 	fetch.max.wait.ms = 500
benchi-kafka-connect  | 	fetch.min.bytes = 1
benchi-kafka-connect  | 	group.id = connect-cluster-group
benchi-kafka-connect  | 	group.instance.id = null
benchi-kafka-connect  | 	group.protocol = classic
benchi-kafka-connect  | 	group.remote.assignor = null
benchi-kafka-connect  | 	heartbeat.interval.ms = 3000
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	internal.leave.group.on.close = true
benchi-kafka-connect  | 	internal.throw.on.fetch.stable.offset.unsupported = false
benchi-kafka-connect  | 	isolation.level = read_uncommitted
benchi-kafka-connect  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
benchi-kafka-connect  | 	max.partition.fetch.bytes = 1048576
benchi-kafka-connect  | 	max.poll.interval.ms = 300000
benchi-kafka-connect  | 	max.poll.records = 500
benchi-kafka-connect  | 	metadata.max.age.ms = 180000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	session.timeout.ms = 45000
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  |  (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,733] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:32,736] INFO [Producer clientId=connect-cluster-group-configs] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,737] INFO These configurations '[log4j.loggers, auto.create.topics.enable, plugin.path, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, offset.flush.interval.ms, rest.port, config.storage.replication.factor, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:32,737] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,737] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,737] INFO Kafka startTimeMs: 1744907432737 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:32,744] INFO [Consumer clientId=connect-cluster-group-configs, groupId=connect-cluster-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,745] INFO [Consumer clientId=connect-cluster-group-configs, groupId=connect-cluster-group] Assigned to partition(s): benchi-connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
benchi-kafka-connect  | [2025-04-17 16:30:32,745] INFO [Consumer clientId=connect-cluster-group-configs, groupId=connect-cluster-group] Seeking to earliest offset of partition benchi-connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,757] INFO [Consumer clientId=connect-cluster-group-configs, groupId=connect-cluster-group] Resetting offset for partition benchi-connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:32,757] INFO Finished reading KafkaBasedLog for topic benchi-connect-configs (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,757] INFO Started KafkaBasedLog for topic benchi-connect-configs (org.apache.kafka.connect.util.KafkaBasedLog)
benchi-kafka-connect  | [2025-04-17 16:30:32,757] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
benchi-kafka-connect  | [2025-04-17 16:30:32,757] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:32,764] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:32,905] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,907] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,907] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,917] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,917] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Requesting disconnect from last known coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,917] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:32,917] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,018] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
benchi-kafka-connect  | [2025-04-17 16:30:33,020] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,020] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,020] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Requesting disconnect from last known coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,137] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,137] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,140] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,140] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Requesting disconnect from last known coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,141] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,141] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,242] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient)
benchi-kafka-connect  | [2025-04-17 16:30:33,244] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,244] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,244] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Requesting disconnect from last known coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,360] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,360] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,367] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:33,512] INFO 172.25.0.3 - - [17/Apr/2025:16:30:33 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "curl/7.61.1" 70 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:36,377] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully joined group with generation Generation{generationId=1, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:36,405] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully synced group in generation Generation{generationId=1, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:36,405] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', leaderUrl='http://benchi-kafka-connect:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:36,405] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:36,405] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:36,444] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:36,502] INFO [SF_KAFKA_CONNECTOR] Using provided role meroxa_platform_role for JDBC connection. (com.snowflake.kafka.connector.internal.InternalUtils)
benchi-kafka-connect  | [2025-04-17 16:30:36,505] INFO [SF_KAFKA_CONNECTOR] Establishing a JDBC connection with url:jdbc:snowflake://gvpvffj-ng55321.snowflakecomputing.com:443 (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | Apr 17, 2025 4:30:36 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Opening session with server: https://gvpvffj-ng55321.snowflakecomputing.com:443/, account: gvpvffj-ng55321, user: meroxa_user, password is not provided, role: meroxa_platform_role, database: benchi, schema: public, warehouse: null, validate default parameters: null, authenticator: snowflake_jwt, ocsp mode: FAIL_OPEN, passcode in password: null, passcode is not provided, private key is provided, disable socks proxy: null, application: null, app id: JDBC, app version: 3.22.0, login timeout: null, retry timeout: null, network timeout: null, query timeout: null, connection timeout: null, socket timeout: null, tracing: null, private key file: null, private key pwd is not provided, enable_diagnostics: not provided, diagnostics_allowlist_path: null, session parameters: client store temporary credential: null, gzip disabled: null, browser response timeout: null
benchi-kafka-connect  | Apr 17, 2025 4:30:36 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Connecting to GLOBAL Snowflake domain
benchi-kafka-connect  | Apr 17, 2025 4:30:36 PM net.snowflake.client.core.FileUtil logWarnWhenAccessibleByOthers
benchi-kafka-connect  | WARNING: Cache file creation: File /home/appuser/.cache/snowflake/ocsp_response_cache.json is accessible by others to:
benchi-kafka-connect  | Apr 17, 2025 4:30:36 PM net.snowflake.client.core.FileUtil logWarnWhenAccessibleByOthers
benchi-kafka-connect  | WARNING: Read cache: File /home/appuser/.cache/snowflake/ocsp_response_cache.json is accessible by others to:
benchi-kafka-connect  | Apr 17, 2025 4:30:37 PM net.snowflake.client.core.FileUtil logWarnWhenAccessibleByOthers
benchi-kafka-connect  | WARNING: Write to cache: File /home/appuser/.cache/snowflake/ocsp_response_cache.json is accessible by others to:
benchi-kafka-connect  | [2025-04-17 16:30:37,279] INFO [SF_KAFKA_CONNECTOR] initialized the snowflake connection (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:37,501] INFO [SF_KAFKA_CONNECTOR] database benchi exists (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:37,607] INFO [SF_KAFKA_CONNECTOR] schema public exists (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:37,607] INFO [SF_KAFKA_CONNECTOR] Validated config with no error (com.snowflake.kafka.connector.SnowflakeSinkConnector)
benchi-kafka-connect  | [2025-04-17 16:30:37,610] INFO AbstractConfig values: 
benchi-kafka-connect  |  (org.apache.kafka.common.config.AbstractConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,625] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Connector snowflake-sink config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,626] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,626] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,629] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully joined group with generation Generation{generationId=2, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,633] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully synced group in generation Generation{generationId=2, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,633] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', leaderUrl='http://benchi-kafka-connect:8083/', offset=2, connectorIds=[snowflake-sink], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,634] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,635] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Starting connector snowflake-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,638] INFO Creating connector snowflake-sink of type com.snowflake.kafka.connector.SnowflakeSinkConnector (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,638] INFO SinkConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,638] INFO EnrichedConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,639] INFO 127.0.0.1 - - [17/Apr/2025:16:30:33 +0000] "POST /connectors HTTP/1.1" 201 2458 "-" "curl/7.61.1" 3737 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:37,641] INFO Instantiated connector snowflake-sink with version 3.1.1 of type class com.snowflake.kafka.connector.SnowflakeSinkConnector (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,642] INFO Finished creating connector snowflake-sink (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,643] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,643] INFO [SF_KAFKA_CONNECTOR] SnowflakeSinkConnector:starting... (com.snowflake.kafka.connector.SnowflakeSinkConnector)
benchi-kafka-connect  | [2025-04-17 16:30:37,643] INFO [SF_KAFKA_CONNECTOR] Current Snowflake Kafka Connector Version: 3.1.1 (com.snowflake.kafka.connector.Utils)
benchi-kafka-connect  | [2025-04-17 16:30:37,696] WARN [SF_KAFKA_CONNECTOR] Connector update is available, please upgrade Snowflake Kafka Connector (3.1.1 -> 3.1.3)  (com.snowflake.kafka.connector.Utils)
benchi-kafka-connect  | [2025-04-17 16:30:37,697] INFO [SF_KAFKA_CONNECTOR] snowflake.streaming.enable.single.buffer set to default true  (com.snowflake.kafka.connector.SnowflakeSinkConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,697] INFO [SF_KAFKA_CONNECTOR] snowflake.streaming.max.client.lag set to default 30 seconds (com.snowflake.kafka.connector.SnowflakeSinkConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,698] WARN [SF_KAFKA_CONNECTOR] buffer.flush.time parameter value is ignored because internal buffer is disabled. To go back to previous behaviour set snowflake.streaming.enable.single.buffer to false (com.snowflake.kafka.connector.internal.streaming.DefaultStreamingConfigValidator$SingleBufferConfigValidator)
benchi-kafka-connect  | [2025-04-17 16:30:37,698] WARN [SF_KAFKA_CONNECTOR] buffer.count.records parameter value is ignored because internal buffer is disabled. To go back to previous behaviour set snowflake.streaming.enable.single.buffer to false (com.snowflake.kafka.connector.internal.streaming.DefaultStreamingConfigValidator$SingleBufferConfigValidator)
benchi-kafka-connect  | [2025-04-17 16:30:37,710] INFO [SF_KAFKA_CONNECTOR] Using provided role meroxa_platform_role for JDBC connection. (com.snowflake.kafka.connector.internal.InternalUtils)
benchi-kafka-connect  | [2025-04-17 16:30:37,710] INFO [SF_KAFKA_CONNECTOR] Establishing a JDBC connection with url:jdbc:snowflake://gvpvffj-ng55321.snowflakecomputing.com:443 (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | Apr 17, 2025 4:30:37 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Opening session with server: https://gvpvffj-ng55321.snowflakecomputing.com:443/, account: gvpvffj-ng55321, user: meroxa_user, password is not provided, role: meroxa_platform_role, database: benchi, schema: public, warehouse: null, validate default parameters: null, authenticator: snowflake_jwt, ocsp mode: FAIL_OPEN, passcode in password: null, passcode is not provided, private key is provided, disable socks proxy: null, application: null, app id: JDBC, app version: 3.22.0, login timeout: null, retry timeout: null, network timeout: null, query timeout: null, connection timeout: null, socket timeout: null, tracing: null, private key file: null, private key pwd is not provided, enable_diagnostics: not provided, diagnostics_allowlist_path: null, session parameters: client store temporary credential: null, gzip disabled: null, browser response timeout: null
benchi-kafka-connect  | Apr 17, 2025 4:30:37 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Connecting to GLOBAL Snowflake domain
benchi-kafka-connect  | [2025-04-17 16:30:37,801] INFO [SF_KAFKA_CONNECTOR] initialized the snowflake connection (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:37,803] INFO [SF_KAFKA_CONNECTOR] SnowflakeSinkConnector:started (com.snowflake.kafka.connector.SnowflakeSinkConnector)
benchi-kafka-connect  | [2025-04-17 16:30:37,812] INFO SinkConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,812] INFO EnrichedConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,833] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Tasks [snowflake-sink-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,834] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,834] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,836] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully joined group with generation Generation{generationId=3, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,840] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Successfully synced group in generation Generation{generationId=3, memberId='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:37,841] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-benchi-kafka-connect:8083-0efbfdaa-256d-4f99-b960-807f108d6e39', leaderUrl='http://benchi-kafka-connect:8083/', offset=4, connectorIds=[snowflake-sink], taskIds=[snowflake-sink-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,841] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,842] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Starting task snowflake-sink-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,844] INFO Creating task snowflake-sink-0 (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,846] INFO ConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.ConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,847] INFO EnrichedConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,848] INFO TaskConfig values: 
benchi-kafka-connect  | 	task.class = class com.snowflake.kafka.connector.SnowflakeSinkTask
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.TaskConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,848] INFO Instantiated task snowflake-sink-0 with version 3.1.1 of type com.snowflake.kafka.connector.SnowflakeSinkTask (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,849] INFO StringConverterConfig values: 
benchi-kafka-connect  | 	converter.encoding = UTF-8
benchi-kafka-connect  | 	converter.type = key
benchi-kafka-connect  |  (org.apache.kafka.connect.storage.StringConverterConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,849] INFO JsonConverterConfig values: 
benchi-kafka-connect  | 	converter.type = value
benchi-kafka-connect  | 	decimal.format = BASE64
benchi-kafka-connect  | 	replace.null.with.default = true
benchi-kafka-connect  | 	schemas.cache.size = 1000
benchi-kafka-connect  | 	schemas.enable = false
benchi-kafka-connect  |  (org.apache.kafka.connect.json.JsonConverterConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,849] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task snowflake-sink-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,849] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task snowflake-sink-0 using the connector config (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,850] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task snowflake-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,852] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker)
benchi-kafka-connect  | [2025-04-17 16:30:37,852] INFO SinkConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.SinkConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,853] INFO EnrichedConnectorConfig values: 
benchi-kafka-connect  | 	config.action.reload = restart
benchi-kafka-connect  | 	connector.class = com.snowflake.kafka.connector.SnowflakeSinkConnector
benchi-kafka-connect  | 	errors.deadletterqueue.context.headers.enable = false
benchi-kafka-connect  | 	errors.deadletterqueue.topic.name = 
benchi-kafka-connect  | 	errors.deadletterqueue.topic.replication.factor = 3
benchi-kafka-connect  | 	errors.log.enable = false
benchi-kafka-connect  | 	errors.log.include.messages = false
benchi-kafka-connect  | 	errors.retry.delay.max.ms = 60000
benchi-kafka-connect  | 	errors.retry.timeout = 0
benchi-kafka-connect  | 	errors.tolerance = none
benchi-kafka-connect  | 	header.converter = null
benchi-kafka-connect  | 	key.converter = class org.apache.kafka.connect.storage.StringConverter
benchi-kafka-connect  | 	name = snowflake-sink
benchi-kafka-connect  | 	predicates = []
benchi-kafka-connect  | 	tasks.max = 1
benchi-kafka-connect  | 	tasks.max.enforce = true
benchi-kafka-connect  | 	topics = [snowflake.test.users]
benchi-kafka-connect  | 	topics.regex = 
benchi-kafka-connect  | 	transforms = []
benchi-kafka-connect  | 	value.converter = class org.apache.kafka.connect.json.JsonConverter
benchi-kafka-connect  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,854] INFO ConsumerConfig values: 
benchi-kafka-connect  | 	allow.auto.create.topics = true
benchi-kafka-connect  | 	auto.commit.interval.ms = 5000
benchi-kafka-connect  | 	auto.include.jmx.reporter = true
benchi-kafka-connect  | 	auto.offset.reset = earliest
benchi-kafka-connect  | 	bootstrap.servers = [benchi-kafka:9092]
benchi-kafka-connect  | 	check.crcs = true
benchi-kafka-connect  | 	client.dns.lookup = use_all_dns_ips
benchi-kafka-connect  | 	client.id = connector-consumer-snowflake-sink-0
benchi-kafka-connect  | 	client.rack = 
benchi-kafka-connect  | 	connections.max.idle.ms = 540000
benchi-kafka-connect  | 	default.api.timeout.ms = 60000
benchi-kafka-connect  | 	enable.auto.commit = false
benchi-kafka-connect  | 	enable.metrics.push = true
benchi-kafka-connect  | 	exclude.internal.topics = true
benchi-kafka-connect  | 	fetch.max.bytes = 52428800
benchi-kafka-connect  | 	fetch.max.wait.ms = 500
benchi-kafka-connect  | 	fetch.min.bytes = 1
benchi-kafka-connect  | 	group.id = connect-snowflake-sink
benchi-kafka-connect  | 	group.instance.id = null
benchi-kafka-connect  | 	group.protocol = classic
benchi-kafka-connect  | 	group.remote.assignor = null
benchi-kafka-connect  | 	heartbeat.interval.ms = 3000
benchi-kafka-connect  | 	interceptor.classes = []
benchi-kafka-connect  | 	internal.leave.group.on.close = true
benchi-kafka-connect  | 	internal.throw.on.fetch.stable.offset.unsupported = false
benchi-kafka-connect  | 	isolation.level = read_uncommitted
benchi-kafka-connect  | 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  | 	max.partition.fetch.bytes = 1048576
benchi-kafka-connect  | 	max.poll.interval.ms = 300000
benchi-kafka-connect  | 	max.poll.records = 500
benchi-kafka-connect  | 	metadata.max.age.ms = 300000
benchi-kafka-connect  | 	metadata.recovery.strategy = none
benchi-kafka-connect  | 	metric.reporters = []
benchi-kafka-connect  | 	metrics.num.samples = 2
benchi-kafka-connect  | 	metrics.recording.level = INFO
benchi-kafka-connect  | 	metrics.sample.window.ms = 30000
benchi-kafka-connect  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
benchi-kafka-connect  | 	receive.buffer.bytes = 65536
benchi-kafka-connect  | 	reconnect.backoff.max.ms = 1000
benchi-kafka-connect  | 	reconnect.backoff.ms = 50
benchi-kafka-connect  | 	request.timeout.ms = 30000
benchi-kafka-connect  | 	retry.backoff.max.ms = 1000
benchi-kafka-connect  | 	retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.client.callback.handler.class = null
benchi-kafka-connect  | 	sasl.jaas.config = null
benchi-kafka-connect  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
benchi-kafka-connect  | 	sasl.kerberos.min.time.before.relogin = 60000
benchi-kafka-connect  | 	sasl.kerberos.service.name = null
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.jitter = 0.05
benchi-kafka-connect  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.callback.handler.class = null
benchi-kafka-connect  | 	sasl.login.class = null
benchi-kafka-connect  | 	sasl.login.connect.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.read.timeout.ms = null
benchi-kafka-connect  | 	sasl.login.refresh.buffer.seconds = 300
benchi-kafka-connect  | 	sasl.login.refresh.min.period.seconds = 60
benchi-kafka-connect  | 	sasl.login.refresh.window.factor = 0.8
benchi-kafka-connect  | 	sasl.login.refresh.window.jitter = 0.05
benchi-kafka-connect  | 	sasl.login.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.login.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.mechanism = GSSAPI
benchi-kafka-connect  | 	sasl.oauthbearer.clock.skew.seconds = 30
benchi-kafka-connect  | 	sasl.oauthbearer.expected.audience = null
benchi-kafka-connect  | 	sasl.oauthbearer.expected.issuer = null
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
benchi-kafka-connect  | 	sasl.oauthbearer.jwks.endpoint.url = null
benchi-kafka-connect  | 	sasl.oauthbearer.scope.claim.name = scope
benchi-kafka-connect  | 	sasl.oauthbearer.sub.claim.name = sub
benchi-kafka-connect  | 	sasl.oauthbearer.token.endpoint.url = null
benchi-kafka-connect  | 	security.protocol = PLAINTEXT
benchi-kafka-connect  | 	security.providers = null
benchi-kafka-connect  | 	send.buffer.bytes = 131072
benchi-kafka-connect  | 	session.timeout.ms = 45000
benchi-kafka-connect  | 	socket.connection.setup.timeout.max.ms = 30000
benchi-kafka-connect  | 	socket.connection.setup.timeout.ms = 10000
benchi-kafka-connect  | 	ssl.cipher.suites = null
benchi-kafka-connect  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
benchi-kafka-connect  | 	ssl.endpoint.identification.algorithm = https
benchi-kafka-connect  | 	ssl.engine.factory.class = null
benchi-kafka-connect  | 	ssl.key.password = null
benchi-kafka-connect  | 	ssl.keymanager.algorithm = SunX509
benchi-kafka-connect  | 	ssl.keystore.certificate.chain = null
benchi-kafka-connect  | 	ssl.keystore.key = null
benchi-kafka-connect  | 	ssl.keystore.location = null
benchi-kafka-connect  | 	ssl.keystore.password = null
benchi-kafka-connect  | 	ssl.keystore.type = JKS
benchi-kafka-connect  | 	ssl.protocol = TLSv1.3
benchi-kafka-connect  | 	ssl.provider = null
benchi-kafka-connect  | 	ssl.secure.random.implementation = null
benchi-kafka-connect  | 	ssl.trustmanager.algorithm = PKIX
benchi-kafka-connect  | 	ssl.truststore.certificates = null
benchi-kafka-connect  | 	ssl.truststore.location = null
benchi-kafka-connect  | 	ssl.truststore.password = null
benchi-kafka-connect  | 	ssl.truststore.type = JKS
benchi-kafka-connect  | 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
benchi-kafka-connect  |  (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,855] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
benchi-kafka-connect  | [2025-04-17 16:30:37,858] INFO These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
benchi-kafka-connect  | [2025-04-17 16:30:37,859] INFO Kafka version: 7.8.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:37,859] INFO Kafka commitId: 3eb9c1b8442d046f77fcce351e49303422f9a6e9 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:37,859] INFO Kafka startTimeMs: 1744907437858 (org.apache.kafka.common.utils.AppInfoParser)
benchi-kafka-connect  | [2025-04-17 16:30:37,866] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Subscribed to topic(s): snowflake.test.users (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
benchi-kafka-connect  | [2025-04-17 16:30:37,866] INFO [Worker clientId=connect-benchi-kafka-connect:8083, groupId=connect-cluster-group] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
benchi-kafka-connect  | [2025-04-17 16:30:37,866] INFO [SF_KAFKA_CONNECTOR] starting task... (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:37,867] INFO [SF_KAFKA_CONNECTOR] Errant record reporter is not configured. (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:37,877] INFO [SF_KAFKA_CONNECTOR] Using provided role meroxa_platform_role for JDBC connection. (com.snowflake.kafka.connector.internal.InternalUtils)
benchi-kafka-connect  | [2025-04-17 16:30:37,877] INFO [SF_KAFKA_CONNECTOR] Establishing a JDBC connection with url:jdbc:snowflake://gvpvffj-ng55321.snowflakecomputing.com:443 (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | Apr 17, 2025 4:30:37 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Opening session with server: https://gvpvffj-ng55321.snowflakecomputing.com:443/, account: gvpvffj-ng55321, user: meroxa_user, password is not provided, role: meroxa_platform_role, database: benchi, schema: public, warehouse: null, validate default parameters: null, authenticator: snowflake_jwt, ocsp mode: FAIL_OPEN, passcode in password: null, passcode is not provided, private key is provided, disable socks proxy: null, application: null, app id: JDBC, app version: 3.22.0, login timeout: null, retry timeout: null, network timeout: null, query timeout: null, connection timeout: null, socket timeout: null, tracing: null, private key file: null, private key pwd is not provided, enable_diagnostics: not provided, diagnostics_allowlist_path: null, session parameters: client store temporary credential: null, gzip disabled: null, browser response timeout: null
benchi-kafka-connect  | Apr 17, 2025 4:30:37 PM net.snowflake.client.core.SFSession open
benchi-kafka-connect  | INFO: Connecting to GLOBAL Snowflake domain
benchi-kafka-connect  | [2025-04-17 16:30:38,058] INFO [SF_KAFKA_CONNECTOR] initialized the snowflake connection (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:38,084] INFO [SF_KAFKA_CONNECTOR] Streaming Client Config is overridden for max_channel_size_in_bytes=5000000 (com.snowflake.kafka.connector.internal.streaming.StreamingClientProperties)
benchi-kafka-connect  | [2025-04-17 16:30:38,084] INFO [SF_KAFKA_CONNECTOR] Streaming Client Config is overridden for max_client_lag=30 second (com.snowflake.kafka.connector.internal.streaming.StreamingClientProperties)
benchi-kafka-connect  | [2025-04-17 16:30:38,086] INFO [SF_KAFKA_CONNECTOR] Initializing Streaming Client... (com.snowflake.kafka.connector.internal.streaming.DirectStreamingClientHandler)
benchi-kafka-connect  | [2025-04-17 16:30:38,133] INFO 127.0.0.1 - - [17/Apr/2025:16:30:38 +0000] "GET /connectors/snowflake-sink/status HTTP/1.1" 200 122 "-" "curl/7.61.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:38,205] INFO Default user agent SnowpipeJavaSDK/3.1.1 (Linux 6.1.132-147.221.amzn2023.x86_64 amd64) JAVA/17.0.13 (net.snowflake.ingest.connection.RequestBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,239] INFO Successfully created new JWT (net.snowflake.ingest.connection.SecurityManager)
benchi-kafka-connect  | [2025-04-17 16:30:38,240] INFO Creating a RequestBuilder with arguments : Account : GVPVFFJ-NG55321, User : MEROXA_USER, Scheme : https, Host : gvpvffj-ng55321.snowflakecomputing.com, Port : 443, userAgentSuffix: null (net.snowflake.ingest.connection.RequestBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,240] INFO [SF_INGEST] Using KEYPAIR_JWT for authorization (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:38,503] INFO [SF_INGEST] Create 24 threads for build/upload blobs for client=KC_CLIENT_snowflake_sink_1996731346_0, total available processors=8 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:38,503] INFO [SF_INGEST] Client created, name=KC_CLIENT_snowflake_sink_1996731346_0, account=gvpvffj-ng55321. isTestMode=false, parameters=ParameterProvider{parameterMap={max_channel_size_in_bytes=5000000, max_client_lag=30 second}} (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:38,504] INFO [SF_KAFKA_CONNECTOR] Successfully initialized Streaming Client:KC_CLIENT_snowflake_sink_1996731346 with properties [role=meroxa_platform_role, user=meroxa_user, url=GVPVFFJ-NG55321.snowflakecomputing.com] (com.snowflake.kafka.connector.internal.streaming.DirectStreamingClientHandler)
benchi-kafka-connect  | [2025-04-17 16:30:38,505] INFO [SF_KAFKA_CONNECTOR] Streaming client optimization is enabled per worker node, KC will reuse valid clients when possible. Returning client with name: KC_CLIENT_snowflake_sink_1996731346_0 (com.snowflake.kafka.connector.internal.streaming.StreamingClientProvider)
benchi-kafka-connect  | [2025-04-17 16:30:38,508] INFO [SF_KAFKA_CONNECTOR] com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2 created (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,508] INFO [SF_KAFKA_CONNECTOR] set buffer size limitation to 5000000 bytes (com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2)
benchi-kafka-connect  | [2025-04-17 16:30:38,508] INFO [SF_KAFKA_CONNECTOR] file size is limited to 5000000 (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,508] INFO [SF_KAFKA_CONNECTOR] Set number of records for buffer threshold to 10000 (com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2)
benchi-kafka-connect  | [2025-04-17 16:30:38,508] INFO [SF_KAFKA_CONNECTOR] record number is limited to 10000 (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] set flush time to 60 seconds (com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] flush time is limited to 60 (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] set topic 2 table map 
benchi-kafka-connect  |   (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] metadata config map is SnowflakeMetadataConfig{createtimeFlag=true, connectorPushTimeFlag=true, topicFlag=true, offsetAndPartitionFlag=true, allFlag=true} (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] Config Behavior on null value is default (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] Config JMX value true. (true = Enabled, false = Disabled) (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] com.snowflake.kafka.connector.internal.SnowflakeSinkService created (com.snowflake.kafka.connector.internal.SnowflakeSinkServiceFactory$SnowflakeSinkServiceBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO [SF_KAFKA_CONNECTOR] task started, execution time: 0 milliseconds (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:38,509] INFO WorkerSinkTask{id=snowflake-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:38,511] INFO WorkerSinkTask{id=snowflake-sink-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:38,517] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Cluster ID: 5L6g3nShT-eMCtK--X86sw (org.apache.kafka.clients.Metadata)
benchi-kafka-connect  | [2025-04-17 16:30:38,530] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Discovered group coordinator benchi-kafka:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:38,531] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:38,539] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Request joining group due to: need to re-join with the given member-id: connector-consumer-snowflake-sink-0-5397a592-a5e4-43a4-aa69-dc88ec660ae0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:38,539] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:38,604] INFO 172.25.0.3 - - [17/Apr/2025:16:30:38 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:41,543] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-snowflake-sink-0-5397a592-a5e4-43a4-aa69-dc88ec660ae0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:41,549] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Finished assignment for group at generation 1: {connector-consumer-snowflake-sink-0-5397a592-a5e4-43a4-aa69-dc88ec660ae0=Assignment(partitions=[snowflake.test.users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:41,555] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-snowflake-sink-0-5397a592-a5e4-43a4-aa69-dc88ec660ae0', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:41,555] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Notifying assignor about the new Assignment(partitions=[snowflake.test.users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:41,555] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Adding newly assigned partitions: snowflake.test.users-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker)
benchi-kafka-connect  | [2025-04-17 16:30:41,567] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Found no committed offset for partition snowflake.test.users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator)
benchi-kafka-connect  | [2025-04-17 16:30:41,573] INFO [Consumer clientId=connector-consumer-snowflake-sink-0, groupId=connect-snowflake-sink] Resetting offset for partition snowflake.test.users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[benchi-kafka:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
benchi-kafka-connect  | [2025-04-17 16:30:41,667] INFO [SF_KAFKA_CONNECTOR] Creating new table snowflake_test_users_665962952. (com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2)
benchi-kafka-connect  | [2025-04-17 16:30:41,911] INFO [SF_KAFKA_CONNECTOR] create table snowflake_test_users_665962952 (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:41,919] INFO [SF_KAFKA_CONNECTOR] [SCHEMA_EVOLUTION_CACHE] Schematization disabled. Setting false for table snowflake_test_users_665962952 (com.snowflake.kafka.connector.internal.streaming.SnowflakeSinkServiceV2)
benchi-kafka-connect  | [2025-04-17 16:30:42,236] INFO [SF_KAFKA_CONNECTOR] Migrate OffsetToken response for table:snowflake_test_users_665962952, sourceChannel:snowflake_sink_1996731346_snowflake.test.users_0, destinationChannel:snowflake.test.users_0 is:ChannelMigrateOffsetTokenResponseDTO{responseCode=51, responseMessage='Source Channel does not exist for Offset Migration'} (com.snowflake.kafka.connector.internal.SnowflakeConnectionServiceV1)
benchi-kafka-connect  | [2025-04-17 16:30:42,241] INFO [SF_KAFKA_CONNECTOR] Opening a channel with name:snowflake.test.users_0 for table name:snowflake_test_users_665962952 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:30:42,520] INFO [SF_INGEST] Open channel request succeeded, channel=snowflake.test.users_0, table=benchi.public.snowflake_test_users_665962952, clientSequencer=0, rowSequencer=0, client=KC_CLIENT_snowflake_sink_1996731346_0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:42,528] INFO [SF_INGEST] Channel=SNOWFLAKE.TEST.USERS_0 created for table=SNOWFLAKE_TEST_USERS_665962952 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestChannelInternal)
benchi-kafka-connect  | [2025-04-17 16:30:42,725] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:null (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:30:42,733] INFO [SF_KAFKA_CONNECTOR] TopicPartitionChannel:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset token is NULL, will rely on Kafka to send us the correct offset instead (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:30:42,733] INFO [SF_KAFKA_CONNECTOR] task opened with 1 partitions, execution time: 1160 milliseconds (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:43,742] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec fileRegistrationPath=2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:43,802] INFO 172.25.0.3 - - [17/Apr/2025:16:30:43 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 3 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:30:43,880] WARN Unable to load native-hadoop library for your platform... using builtin-java classes where applicable (net.snowflake.ingest.internal.apache.hadoop.util.NativeCodeLoader)
benchi-kafka-connect  | [2025-04-17 16:30:43,926] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:44,246] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec fileRegistrationPath=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 0] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:44,262] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:44,598] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22703, startOffset=0, estimatedUncompressedSize=5051417.5, md5=749393343fdb0f24805de44ce5edd40d, chunkLength=142777, compressedSize=142784, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:44,598] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=24998, startOffset=0, estimatedUncompressedSize=5539839.0, md5=89daa8be22b87007d3527a00c08b9ce7, chunkLength=159228, compressedSize=159232, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:44,612] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec, size=159232 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:44,615] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, size=142784 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:44,744] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec fileRegistrationPath=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 3, active threads = 3, queued tasks = 0, completed tasks = 0] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:44,769] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:44,846] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=27070, startOffset=0, estimatedUncompressedSize=6023075.0, md5=1d1c32e039955a040ba3716e1c7bd9ca, chunkLength=169899, compressedSize=169904, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:44,847] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, size=169904 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:44 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:44 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:44 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec
benchi-kafka-connect  | [2025-04-17 16:30:45,151] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec fileRegistrationPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 4, active threads = 4, queued tasks = 0, completed tasks = 0] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,164] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec. It took 330 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:45,209] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec, size=159232, timeInMillis=596, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,209] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec. It took 330 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:45,209] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, size=142784, timeInMillis=585, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,209] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec. It took 332 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:45,214] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, size=169904, timeInMillis=367, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,238] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=25465, startOffset=0, estimatedUncompressedSize=5666435.5, md5=f06b8a55d15d356cfaaa3adc86540db3, chunkLength=159565, compressedSize=159568, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:45,238] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec, size=159568 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec
benchi-kafka-connect  | [2025-04-17 16:30:45,368] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf77_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_0.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec. It took 171 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:45,415] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec, size=159568, timeInMillis=177, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,415] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=3, currentBlobListSize=3, idx=3 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:45,415] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, 2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, 2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:45,517] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_1.bdec, 2025/4/17/16/30/suvf78_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_2.bdec, 2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_3.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:45,548] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec fileRegistrationPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 5, active threads = 1, queued tasks = 0, completed tasks = 4] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,553] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:45,630] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23690, startOffset=0, estimatedUncompressedSize=5318405.0, md5=d54dafae899ccb8ec0ec26548dcabf1a, chunkLength=148350, compressedSize=148352, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:45,630] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec, size=148352 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:45 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec. It took 204 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:45,840] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec, size=148352, timeInMillis=209, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,840] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:45,840] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:45,901] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_4.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:45,956] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec fileRegistrationPath=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 6, active threads = 1, queued tasks = 0, completed tasks = 5] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:45,960] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:46,061] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29027, startOffset=0, estimatedUncompressedSize=6516561.5, md5=de0533f2fa3777266a724a8cf4c63eaa, chunkLength=181105, compressedSize=181120, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:46,063] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec, size=181120 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:46 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:46 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec. It took 205 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:46,277] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec, size=181120, timeInMillis=214, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:46,278] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:46,278] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:46,353] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf79_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_5.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:46,358] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec fileRegistrationPath=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 7, active threads = 1, queued tasks = 0, completed tasks = 6] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:46,364] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:46,466] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=27736, startOffset=0, estimatedUncompressedSize=6226732.0, md5=3d0321c5c3a7dcc84873fde46cc71cf2, chunkLength=173229, compressedSize=173232, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:46,467] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec, size=173232 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:46 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec
benchi-kafka-connect  | [2025-04-17 16:30:46,733] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec, size=173232, timeInMillis=266, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:46,734] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:46,734] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:46 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec. It took 257 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:46,768] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec fileRegistrationPath=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 8, active threads = 1, queued tasks = 0, completed tasks = 7] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:46,772] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:46,833] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_6.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:46,843] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28315, startOffset=0, estimatedUncompressedSize=6356717.5, md5=894c3504c047dc9b9fbc9689996aa2ad, chunkLength=176929, compressedSize=176944, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:46,844] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec, size=176944 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:46 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:47 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec. It took 231 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:47,079] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec, size=176944, timeInMillis=235, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:47,080] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:47,080] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:47,153] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_7.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:47,189] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec fileRegistrationPath=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 9, active threads = 1, queued tasks = 0, completed tasks = 8] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:47,194] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:47,268] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28950, startOffset=0, estimatedUncompressedSize=6499275.0, md5=e675d597fbe4454f5c48f8e6e30676ae, chunkLength=180941, compressedSize=180944, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:47,269] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec, size=180944 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:47 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:47 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec. It took 234 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:47,520] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec, size=180944, timeInMillis=251, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:47,520] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:47,520] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:47,574] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_8.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:47,622] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec fileRegistrationPath=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 10, active threads = 1, queued tasks = 0, completed tasks = 9] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:47,625] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:47,706] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29137, startOffset=0, estimatedUncompressedSize=6541256.5, md5=4936b261136ba7af937afc0d7bbcdfd9, chunkLength=181959, compressedSize=181968, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:47,706] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec, size=181968 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:47 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec
benchi-kafka-connect  | [2025-04-17 16:30:47,868] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:47,908] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:237953 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:30:47,908] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 40 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | Apr 17, 2025 4:30:47 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec. It took 227 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:47,938] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec, size=181968, timeInMillis=232, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:47,938] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:47,938] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:47,988] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_9.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:48,025] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec fileRegistrationPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 11, active threads = 1, queued tasks = 0, completed tasks = 10] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:48,028] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:48,090] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=24705, startOffset=0, estimatedUncompressedSize=5546272.5, md5=c71e150527f4075448b02ff0703ef62c, chunkLength=154586, compressedSize=154592, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:48,091] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec, size=154592 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:48 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:48 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec. It took 205 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:48,303] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec, size=154592, timeInMillis=212, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:48,304] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:48,304] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:48,377] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_10.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:48,433] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec fileRegistrationPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 12, active threads = 1, queued tasks = 0, completed tasks = 11] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:48,436] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:48,518] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29271, startOffset=0, estimatedUncompressedSize=6571339.5, md5=7cfa0f99a87a246f7810a99cd082b32f, chunkLength=182855, compressedSize=182864, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:48,518] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec, size=182864 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:48 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:48 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec. It took 206 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:48,727] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec, size=182864, timeInMillis=209, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:48,728] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:48,728] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:48,800] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_11.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:48,835] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec fileRegistrationPath=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 13, active threads = 1, queued tasks = 0, completed tasks = 12] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:48,839] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:48,914] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29319, startOffset=0, estimatedUncompressedSize=6582115.5, md5=0dae350a21109e5666bc030da58a80ce, chunkLength=183221, compressedSize=183232, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:48,914] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec, size=183232 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:48 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec
benchi-kafka-connect  | [2025-04-17 16:30:49,067] INFO 172.25.0.3 - - [17/Apr/2025:16:30:49 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:30:49 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec. It took 226 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:49,144] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec, size=183232, timeInMillis=230, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:49,144] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:49,145] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:49,198] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_12.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:49,236] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec fileRegistrationPath=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 14, active threads = 1, queued tasks = 0, completed tasks = 13] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:49,240] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:49,314] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28933, startOffset=0, estimatedUncompressedSize=6495458.5, md5=7e34c1be4088ec5d218713eeb9bf2894, chunkLength=180702, compressedSize=180704, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:49,314] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec, size=180704 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:49 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec
benchi-kafka-connect  | [2025-04-17 16:30:49,527] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec, size=180704, timeInMillis=213, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:49 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec. It took 208 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:49,528] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:49,528] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:49,585] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_13.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:49,639] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec fileRegistrationPath=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 15, active threads = 1, queued tasks = 0, completed tasks = 14] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:49,643] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:49,710] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29610, startOffset=0, estimatedUncompressedSize=6647445.0, md5=3fbc600071c075ed945ef7f93ce74994, chunkLength=184797, compressedSize=184800, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:49,711] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec, size=184800 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:49 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:49 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec. It took 180 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:49,895] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec, size=184800, timeInMillis=184, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:49,895] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:49,896] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:49,950] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_14.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:50,039] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec fileRegistrationPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 16, active threads = 1, queued tasks = 0, completed tasks = 15] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:50,043] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:50,113] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28533, startOffset=0, estimatedUncompressedSize=6405658.5, md5=ef1d1ebb83fdaefa9e00ec8db2482d3d, chunkLength=178318, compressedSize=178320, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:50,113] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec, size=178320 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:50 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:50 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec. It took 220 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:50,342] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec, size=178320, timeInMillis=229, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:50,342] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:50,342] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:50,427] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_15.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:50,450] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec fileRegistrationPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 17, active threads = 1, queued tasks = 0, completed tasks = 16] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:50,454] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:50,525] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29640, startOffset=0, estimatedUncompressedSize=6654180.0, md5=c463d93abb054ca8d537ac71fe7ea61d, chunkLength=184981, compressedSize=184992, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:50,525] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec, size=184992 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:50 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:50 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec. It took 207 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:50,737] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec, size=184992, timeInMillis=212, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:50,738] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:50,738] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:50,814] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_16.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:50,851] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec fileRegistrationPath=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 18, active threads = 1, queued tasks = 0, completed tasks = 17] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:50,855] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:50,920] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29651, startOffset=0, estimatedUncompressedSize=6656649.5, md5=392270c68fb4f3f839febc5e89947ece, chunkLength=185190, compressedSize=185200, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:50,921] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec, size=185200 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:50 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec. It took 230 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:51,154] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec, size=185200, timeInMillis=233, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,155] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:51,155] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:51,160] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec fileRegistrationPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 19, active threads = 1, queued tasks = 0, completed tasks = 18] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,163] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:51,212] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22461, startOffset=0, estimatedUncompressedSize=5042494.5, md5=6d9b5070f6c3aae740680e67f7b4938c, chunkLength=140703, compressedSize=140704, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:51,213] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec, size=140704 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,215] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_17.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec. It took 199 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:51,416] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec, size=140704, timeInMillis=202, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,416] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:51,416] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:51,463] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec fileRegistrationPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 20, active threads = 1, queued tasks = 0, completed tasks = 19] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,466] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:51,477] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_18.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:51,524] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22608, startOffset=0, estimatedUncompressedSize=5075496.0, md5=93c90aff039346e5fd60bb0c7ef418e9, chunkLength=141542, compressedSize=141552, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:51,525] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec, size=141552 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec
benchi-kafka-connect  | [2025-04-17 16:30:51,723] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec, size=141552, timeInMillis=198, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,724] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:51,724] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec. It took 195 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:51,775] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_19.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:51,864] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec fileRegistrationPath=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 21, active threads = 1, queued tasks = 0, completed tasks = 20] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:51,867] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:30:51 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec
benchi-kafka-connect  | [2025-04-17 16:30:51,946] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29546, startOffset=0, estimatedUncompressedSize=6633077.0, md5=244e2a53bc0a479332504a89dc69f8eb, chunkLength=184519, compressedSize=184528, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:51,946] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec, size=184528 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:52 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec. It took 233 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:52,184] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec, size=184528, timeInMillis=238, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:52,185] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:52,185] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:52,258] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_20.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:52,267] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec fileRegistrationPath=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 22, active threads = 1, queued tasks = 0, completed tasks = 21] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:52,271] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:52,344] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29469, startOffset=0, estimatedUncompressedSize=6615790.5, md5=f967ca8bebc867ddcbdec56f363ae1b9, chunkLength=183940, compressedSize=183952, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:52,344] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec, size=183952 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:52 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:52 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec. It took 159 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:52,507] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec, size=183952, timeInMillis=163, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:52,508] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:52,508] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:52,578] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_21.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:52,668] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec fileRegistrationPath=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 23, active threads = 1, queued tasks = 0, completed tasks = 22] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:52,671] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:52,743] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28086, startOffset=0, estimatedUncompressedSize=6305307.0, md5=a3c32a36d7dc6a2914bcf297a31cc0be, chunkLength=175545, compressedSize=175552, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:52,744] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec, size=175552 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:52 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec
benchi-kafka-connect  | [2025-04-17 16:30:52,921] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec, size=175552, timeInMillis=177, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:52 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec. It took 171 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:52,922] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:52,922] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:52,981] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_22.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,070] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec fileRegistrationPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 0, completed tasks = 23] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,073] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:53,144] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29860, startOffset=0, estimatedUncompressedSize=6703570.0, md5=63ccc2c2c3b517b2dc06fe9065370acc, chunkLength=186614, compressedSize=186624, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:53,144] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec, size=186624 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec. It took 191 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:53,339] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec, size=186624, timeInMillis=195, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,339] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:53,339] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,369] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec fileRegistrationPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 24] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,373] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:53,420] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_23.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,424] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22399, startOffset=0, estimatedUncompressedSize=5028575.5, md5=26f8acf49be00b6520183c16ea95aae9, chunkLength=140350, compressedSize=140352, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:53,424] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec, size=140352 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec. It took 199 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:53,626] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec, size=140352, timeInMillis=202, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,626] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:53,626] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,670] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec fileRegistrationPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 25] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,673] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:53,676] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_24.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,723] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22434, startOffset=0, estimatedUncompressedSize=5036433.0, md5=7e00acd8995e672a30f47f7e0eb2b9fa, chunkLength=140566, compressedSize=140576, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:53,723] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec, size=140576 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:53 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec. It took 177 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:53,905] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec, size=140576, timeInMillis=182, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,905] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:53,905] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:53,971] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec fileRegistrationPath=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 26] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:53,975] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:53,993] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_25.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:54,035] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22905, startOffset=0, estimatedUncompressedSize=5142172.5, md5=c742a5bc7346dccbea651719a861f6b5, chunkLength=143485, compressedSize=143488, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:54,036] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec, size=143488 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:54 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec
benchi-kafka-connect  | [2025-04-17 16:30:54,144] INFO 172.25.0.3 - - [17/Apr/2025:16:30:54 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:30:54 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec. It took 192 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:54,231] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec, size=143488, timeInMillis=195, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:54,232] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:54,232] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:54,300] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_26.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:54,376] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:54,396] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec fileRegistrationPath=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 0, completed tasks = 27] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:54,443] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=27302, startOffset=0, estimatedUncompressedSize=6129299.0, md5=53b35847831c31c101fbe42604ac2d94, chunkLength=170608, compressedSize=170624, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:54,444] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec, size=170624 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:54 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:54 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec. It took 192 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:54,641] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec, size=170624, timeInMillis=197, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:54,641] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:54,641] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:54,691] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_27.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:54,773] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec fileRegistrationPath=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 28] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:54,777] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:54,849] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29475, startOffset=0, estimatedUncompressedSize=6617137.5, md5=dc605fb54b1aab121c961861b5938475, chunkLength=184043, compressedSize=184048, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:54,850] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec, size=184048 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:54 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:55,036] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec, size=184048, timeInMillis=186, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:55,037] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:55,037] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:55,082] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_28.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:55,182] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec fileRegistrationPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 29] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:55,185] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:55,252] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28626, startOffset=0, estimatedUncompressedSize=6426537.0, md5=890f309e583babfbfc3ba0de8523b7dc, chunkLength=179049, compressedSize=179056, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:55,253] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec, size=179056 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec
benchi-kafka-connect  | [2025-04-17 16:30:55,447] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec, size=179056, timeInMillis=194, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec. It took 189 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:55,448] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:55,448] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:55,582] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec fileRegistrationPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 30] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:55,585] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:55,598] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_29.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:55,657] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29766, startOffset=0, estimatedUncompressedSize=6682467.0, md5=6c76b6211ee36e66fc69207d3ad2bcaf, chunkLength=186008, compressedSize=186016, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:55,657] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec, size=186016 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec
benchi-kafka-connect  | [2025-04-17 16:30:55,889] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec fileRegistrationPath=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 1, completed tasks = 30] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:55,892] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec. It took 245 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:55,907] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec, size=186016, timeInMillis=250, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:55,907] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:55,907] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:55,945] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23041, startOffset=0, estimatedUncompressedSize=5172704.5, md5=18301808f0fdc95eb767ab64d4f363e9, chunkLength=144452, compressedSize=144464, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:55,946] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec, size=144464 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:55 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec
benchi-kafka-connect  | [2025-04-17 16:30:55,985] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_30.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec. It took 173 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:56,122] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec, size=144464, timeInMillis=176, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:56,123] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:56,123] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,173] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_31.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,191] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec fileRegistrationPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 32] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:56,199] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:56,249] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23190, startOffset=0, estimatedUncompressedSize=5206155.0, md5=eadd87322586457552ef246ca355fe14, chunkLength=145296, compressedSize=145312, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:56,251] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec, size=145312 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec. It took 191 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:56,447] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec, size=145312, timeInMillis=196, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:56,447] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:56,447] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,492] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec fileRegistrationPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 33] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:56,495] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:56,506] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_32.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,552] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22542, startOffset=0, estimatedUncompressedSize=5060679.0, md5=b85fa7044a1720409a3a13c1e1fec8d0, chunkLength=141269, compressedSize=141280, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:56,552] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec, size=141280 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec
benchi-kafka-connect  | [2025-04-17 16:30:56,773] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec, size=141280, timeInMillis=221, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec. It took 217 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:56,774] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:56,774] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,791] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec fileRegistrationPath=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 34] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:56,794] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:56,833] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_33.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:56,849] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22584, startOffset=0, estimatedUncompressedSize=5070108.0, md5=b6998b8fda96c8411e98ccaa787f92b2, chunkLength=141551, compressedSize=141552, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:56,850] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec, size=141552 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:56 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec. It took 166 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:57,019] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec, size=141552, timeInMillis=169, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,019] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:57,019] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,091] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec fileRegistrationPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 35] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,094] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:57,094] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_34.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,148] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22772, startOffset=0, estimatedUncompressedSize=5112314.0, md5=67a2b72baf036943f64be55aa4508907, chunkLength=142835, compressedSize=142848, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:57,148] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec, size=142848 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec. It took 202 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:57,355] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec, size=142848, timeInMillis=207, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,355] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:57,355] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,394] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec fileRegistrationPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 36] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,397] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:57,439] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_35.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,461] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23272, startOffset=0, estimatedUncompressedSize=5224564.0, md5=3d07fa9e95dc33c6f73f2bd4447fed57, chunkLength=145717, compressedSize=145728, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:57,461] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec, size=145728 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec
benchi-kafka-connect  | [2025-04-17 16:30:57,667] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec, size=145728, timeInMillis=206, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec. It took 202 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:57,668] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:57,668] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,694] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec fileRegistrationPath=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 37] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,697] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:57,721] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_36.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:57,754] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22661, startOffset=0, estimatedUncompressedSize=5090899.5, md5=aef6bc90f2e1af2d1e46c2399d73e9b3, chunkLength=142217, compressedSize=142224, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:57,755] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec, size=142224 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec
benchi-kafka-connect  | [2025-04-17 16:30:57,868] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:30:57,916] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:955818 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:30:57,916] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 48 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | Apr 17, 2025 4:30:57 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec. It took 178 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:57,937] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec, size=142224, timeInMillis=181, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:57,937] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:57,937] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,000] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_37.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,095] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec fileRegistrationPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 38] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:58,099] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:58,165] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=26724, startOffset=0, estimatedUncompressedSize=6052986.0, md5=99caa662963e934a7288e6657c358961, chunkLength=167634, compressedSize=167648, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:58,166] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec, size=167648 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec
benchi-kafka-connect  | [2025-04-17 16:30:58,359] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec, size=167648, timeInMillis=193, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec. It took 190 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:58,360] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:58,360] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,395] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec fileRegistrationPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 39] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:58,400] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:58,441] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_38.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,451] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22172, startOffset=0, estimatedUncompressedSize=5021958.0, md5=ecdd279b359fb4a9bf0b216598b6b709, chunkLength=138904, compressedSize=138912, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:58,451] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec, size=138912 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec. It took 170 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:58,625] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec, size=138912, timeInMillis=174, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:58,626] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:58,626] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,692] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_39.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,695] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec fileRegistrationPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 40] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:58,697] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:58,747] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22592, startOffset=0, estimatedUncompressedSize=5117088.0, md5=570b7af74a408db43be398597dbe3fb3, chunkLength=141638, compressedSize=141648, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:58,748] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec, size=141648 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec
benchi-kafka-connect  | [2025-04-17 16:30:58,899] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec, size=141648, timeInMillis=151, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:58 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec. It took 148 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:58,900] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:58,900] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,953] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_40.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:58,997] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec fileRegistrationPath=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 41] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,001] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:59,066] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23283, startOffset=0, estimatedUncompressedSize=5273599.5, md5=a5eab4fae69e332adf73930a2a7909c8, chunkLength=145708, compressedSize=145712, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:59,067] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec, size=145712 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec
benchi-kafka-connect  | [2025-04-17 16:30:59,243] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec, size=145712, timeInMillis=176, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec. It took 164 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:59,243] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:59,243] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,298] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec fileRegistrationPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 42] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,298] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_41.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,301] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:59,359] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22765, startOffset=0, estimatedUncompressedSize=5156272.5, md5=745f16dc20bb0530da8291afcaf6d2e8, chunkLength=142548, compressedSize=142560, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:59,360] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec, size=142560 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec
benchi-kafka-connect  | [2025-04-17 16:30:59,414] INFO 172.25.0.3 - - [17/Apr/2025:16:30:59 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec. It took 197 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:59,561] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec, size=142560, timeInMillis=201, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,561] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:59,561] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,597] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec fileRegistrationPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 43] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,600] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:59,606] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_42.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,653] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22813, startOffset=0, estimatedUncompressedSize=5167144.5, md5=4f355a2ca96855589b11b61adc484fb3, chunkLength=143055, compressedSize=143056, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:59,653] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec, size=143056 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:30:59,831] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec, size=143056, timeInMillis=178, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,831] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:30:59,831] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,903] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec fileRegistrationPath=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 44] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:30:59,905] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_43.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:30:59,906] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:30:59,956] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23099, startOffset=0, estimatedUncompressedSize=5231923.5, md5=1a77524d8b4f0652133071cba8deb4aa, chunkLength=144629, compressedSize=144640, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:30:59,957] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec, size=144640 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:30:59 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec
benchi-kafka-connect  | [2025-04-17 16:31:00,140] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec, size=144640, timeInMillis=183, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec. It took 180 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:00,140] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:00,140] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,207] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec fileRegistrationPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 45] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:00,210] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:00,216] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/30/suvf7n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_44.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,269] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23589, startOffset=0, estimatedUncompressedSize=5342908.5, md5=6d60ec287bcc4691fa4b9f548e840315, chunkLength=147507, compressedSize=147520, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:00,270] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec, size=147520 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:00,449] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec, size=147520, timeInMillis=179, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:00,449] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:00,449] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,497] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_45.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,506] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec fileRegistrationPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 46] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:00,510] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:00,564] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22314, startOffset=0, estimatedUncompressedSize=5054121.0, md5=d48708707b1099c1b4ffbf56ac9a24e2, chunkLength=139802, compressedSize=139808, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:00,564] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec, size=139808 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec. It took 184 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:00,753] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec, size=139808, timeInMillis=189, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:00,754] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:00,754] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,805] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_46.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:00,806] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec fileRegistrationPath=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 47] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:00,809] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:00,860] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22516, startOffset=0, estimatedUncompressedSize=5099874.0, md5=e97dc0113ae3c64c49d11ce82b79045c, chunkLength=140876, compressedSize=140880, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:00,861] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec, size=140880 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:00 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec. It took 177 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:01,041] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec, size=140880, timeInMillis=180, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,041] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:01,041] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,100] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_47.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,207] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec fileRegistrationPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 48] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,210] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:01,273] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28524, startOffset=0, estimatedUncompressedSize=6460686.0, md5=fc84735bd4f6484345601917e8dcd355, chunkLength=178161, compressedSize=178176, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:01,273] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec, size=178176 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec. It took 185 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:01,462] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec, size=178176, timeInMillis=188, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,463] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:01,463] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,509] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec fileRegistrationPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 49] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,512] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:01,531] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_48.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,579] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23439, startOffset=0, estimatedUncompressedSize=5308933.5, md5=6ff3a57fd330de6b371d2ec13f741bef, chunkLength=146623, compressedSize=146624, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:01,579] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec, size=146624 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:01,759] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec, size=146624, timeInMillis=180, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,759] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:01,759] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,810] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec fileRegistrationPath=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 50] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:01,813] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:01,830] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_49.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:01,871] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22661, startOffset=0, estimatedUncompressedSize=5132716.5, md5=9196df85261acb7b532292b34ddfea05, chunkLength=142007, compressedSize=142016, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:01,871] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec, size=142016 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:01 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec. It took 178 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:02,053] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec, size=142016, timeInMillis=182, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,054] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:02,054] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,110] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec fileRegistrationPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 51] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,113] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:02,113] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_50.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,170] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22448, startOffset=0, estimatedUncompressedSize=5084472.0, md5=5e5fa395a3ccff8aa368faddcf54ebda, chunkLength=140492, compressedSize=140496, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:02,170] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec, size=140496 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec. It took 193 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:02,367] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec, size=140496, timeInMillis=197, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,367] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:02,368] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,410] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec fileRegistrationPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 52] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,413] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:02,437] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_51.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,463] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22805, startOffset=0, estimatedUncompressedSize=5165332.5, md5=88b69849a4ff759288b84e3996be27b9, chunkLength=142750, compressedSize=142752, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:02,463] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec, size=142752 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec
benchi-kafka-connect  | [2025-04-17 16:31:02,639] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec, size=142752, timeInMillis=176, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec. It took 173 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:02,640] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:02,640] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,690] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_52.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:02,712] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec fileRegistrationPath=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 53] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,716] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:02,785] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23319, startOffset=0, estimatedUncompressedSize=5281753.5, md5=8764b27c1bd41188325d0e6811f3f18b, chunkLength=145909, compressedSize=145920, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:02,785] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec, size=145920 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:02 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec. It took 141 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:02,930] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec, size=145920, timeInMillis=145, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:02,931] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:02,931] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,012] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec fileRegistrationPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 54] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:03,015] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:03,023] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7q_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_53.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,071] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22235, startOffset=0, estimatedUncompressedSize=5036227.5, md5=373e8ae613a12adab0a5a4ace9e4429a, chunkLength=139386, compressedSize=139392, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:03,071] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec, size=139392 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:03 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:03 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec. It took 123 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:03,198] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec, size=139392, timeInMillis=127, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:03,198] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:03,198] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,261] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_54.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,414] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec fileRegistrationPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 55] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:03,416] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:03,489] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29713, startOffset=0, estimatedUncompressedSize=6729994.5, md5=81a289b14a8c0c876e163186400c6358, chunkLength=185548, compressedSize=185552, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:03,490] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec, size=185552 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:03 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec
benchi-kafka-connect  | [2025-04-17 16:31:03,626] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec, size=185552, timeInMillis=136, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:03 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec. It took 133 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:03,627] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:03,627] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,682] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_55.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:03,814] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec fileRegistrationPath=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 56] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:03,817] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:03,889] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29736, startOffset=0, estimatedUncompressedSize=6735204.0, md5=c258d00812ead0830727745f70843667, chunkLength=185696, compressedSize=185712, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:03,889] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec, size=185712 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:03 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec. It took 215 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:04,107] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec, size=185712, timeInMillis=218, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,108] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:04,108] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,179] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7r_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_56.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,215] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec fileRegistrationPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 57] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,218] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:04,287] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29593, startOffset=0, estimatedUncompressedSize=6702814.5, md5=ab44df102a1082d046ce5d7fa784e8ac, chunkLength=184728, compressedSize=184736, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:04,288] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec, size=184736 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec. It took 199 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:04,491] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec, size=184736, timeInMillis=203, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,491] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:04,491] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,514] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec fileRegistrationPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 58] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,517] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:04,565] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_57.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,568] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22563, startOffset=0, estimatedUncompressedSize=5110519.5, md5=aede198bea694faaca523a29b55d46d9, chunkLength=141137, compressedSize=141152, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:04,568] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec, size=141152 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec
benchi-kafka-connect  | [2025-04-17 16:31:04,575] INFO 172.25.0.3 - - [17/Apr/2025:16:31:04 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec. It took 197 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:04,769] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec, size=141152, timeInMillis=201, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,769] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:04,769] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,819] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec fileRegistrationPath=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 59] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:04,821] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:04,841] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_58.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:04,870] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22928, startOffset=0, estimatedUncompressedSize=5193192.0, md5=75f381085acf8005e3c7d127b2103acf, chunkLength=143431, compressedSize=143440, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:04,871] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec, size=143440 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:04 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec. It took 171 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:05,046] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec, size=143440, timeInMillis=175, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,046] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:05,046] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,106] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7s_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_59.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,223] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec fileRegistrationPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 60] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,227] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:05,302] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29201, startOffset=0, estimatedUncompressedSize=6614026.5, md5=a816759793905949f2dae5fc6d659761, chunkLength=182279, compressedSize=182288, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:05,302] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec, size=182288 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:05,488] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec, size=182288, timeInMillis=186, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,488] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:05,488] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,524] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec fileRegistrationPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 61] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,527] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:05,548] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_60.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,583] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22122, startOffset=0, estimatedUncompressedSize=5010633.0, md5=1c7802a7e446cb9898f434085ee486ed, chunkLength=138599, compressedSize=138608, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:05,584] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec, size=138608 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec. It took 170 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:05,757] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec, size=138608, timeInMillis=173, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,758] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:05,758] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,809] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_61.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:05,821] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec fileRegistrationPath=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 62] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:05,825] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:05,879] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22280, startOffset=0, estimatedUncompressedSize=5046420.0, md5=bffa1de3ba64d203bbeb7c574232f241, chunkLength=139735, compressedSize=139744, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:05,880] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec, size=139744 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:05 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec. It took 192 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:06,075] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec, size=139744, timeInMillis=195, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,076] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:06,076] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,121] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec fileRegistrationPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 63] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,124] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:06,146] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7t_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_62.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,175] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22221, startOffset=0, estimatedUncompressedSize=5033056.5, md5=791aed5109eacc2e61bf5734e766a541, chunkLength=139250, compressedSize=139264, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:06,175] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec, size=139264 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec. It took 160 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:06,339] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec, size=139264, timeInMillis=164, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,339] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:06,339] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,417] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_63.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,425] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec fileRegistrationPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 64] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,428] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:06,494] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23204, startOffset=0, estimatedUncompressedSize=5255706.0, md5=19ea4653d8454079ec5ec3bcaca6170e, chunkLength=145143, compressedSize=145152, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:06,494] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec, size=145152 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec. It took 204 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:06,703] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec, size=145152, timeInMillis=209, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,703] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:06,703] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,724] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec fileRegistrationPath=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 65] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,727] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:06,752] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_64.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:06,784] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22328, startOffset=0, estimatedUncompressedSize=5057292.0, md5=6ec4552385c89e27490437a4cde62f01, chunkLength=139918, compressedSize=139920, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:06,784] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec, size=139920 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:06 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec. It took 157 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:06,945] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec, size=139920, timeInMillis=161, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:06,945] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:06,946] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:07,003] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7u_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_65.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:07,125] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec fileRegistrationPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 66] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:07,127] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:07,198] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29524, startOffset=0, estimatedUncompressedSize=6687186.0, md5=a4bce1a4042c5affa98786a1616e8403, chunkLength=184486, compressedSize=184496, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:07,199] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec, size=184496 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec. It took 157 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:07,360] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec, size=184496, timeInMillis=161, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:07,360] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:07,360] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:07,424] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec fileRegistrationPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 67] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:07,426] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_66.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:07,428] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:07,480] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22645, startOffset=0, estimatedUncompressedSize=5129092.5, md5=463ef02440fb2bf4740b6c0826daa5ec, chunkLength=141829, compressedSize=141840, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:07,480] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec, size=141840 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec. It took 187 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:07,671] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec, size=141840, timeInMillis=191, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:07,672] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:07,672] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:07,724] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec fileRegistrationPath=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 68] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:07,727] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:07,779] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22887, startOffset=0, estimatedUncompressedSize=5183905.5, md5=0d24f703cc142cff42bd6bcadd0944a4, chunkLength=143415, compressedSize=143424, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:07,780] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec, size=143424 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec
benchi-kafka-connect  | [2025-04-17 16:31:07,869] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:07,965] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec, size=143424, timeInMillis=185, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:07 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:07,984] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:1704462 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:31:07,984] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 115 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:08,012] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_67.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,012] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:08,012] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,075] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7v_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_68.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,225] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec fileRegistrationPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 69] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:08,229] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:08,291] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29296, startOffset=0, estimatedUncompressedSize=6635544.0, md5=c16f226493f35e825170fa204e119bc0, chunkLength=182916, compressedSize=182928, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:08,291] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec, size=182928 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:08 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:08 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec. It took 195 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:08,490] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec, size=182928, timeInMillis=199, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:08,491] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:08,491] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,529] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec fileRegistrationPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 70] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:08,531] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:08,541] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_69.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,589] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22207, startOffset=0, estimatedUncompressedSize=5029885.5, md5=0be8dfbee3a39e5ae047681aed61b1fc, chunkLength=139054, compressedSize=139056, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:08,589] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec, size=139056 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:08 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:08 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec. It took 146 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:08,739] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec, size=139056, timeInMillis=150, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:08,740] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:08,740] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,797] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_70.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:08,828] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec fileRegistrationPath=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 71] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:08,831] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:08,890] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22957, startOffset=0, estimatedUncompressedSize=5199760.5, md5=99ca52320c4c2f00846f734e389f7e35, chunkLength=143793, compressedSize=143808, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:08,890] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec, size=143808 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:08 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec. It took 167 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:09,061] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec, size=143808, timeInMillis=171, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,062] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:09,062] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,114] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7w_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_71.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,132] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec fileRegistrationPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 72] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,135] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:09,187] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23073, startOffset=0, estimatedUncompressedSize=5226034.5, md5=84d6992629b3735ca9f9d21aed6fd79d, chunkLength=144466, compressedSize=144480, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:09,187] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec, size=144480 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec. It took 168 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:09,359] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec, size=144480, timeInMillis=171, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,359] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:09,359] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,434] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec fileRegistrationPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 73] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,443] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:09,455] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_72.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,493] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23288, startOffset=0, estimatedUncompressedSize=5274732.0, md5=3a4c18ba788a0ac1176afaf2169d5f2f, chunkLength=145799, compressedSize=145808, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:09,494] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec, size=145808 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec. It took 174 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:09,672] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec, size=145808, timeInMillis=178, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,672] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:09,672] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,735] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec fileRegistrationPath=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 74] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:09,738] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:09,753] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_73.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:09,784] INFO 172.25.0.3 - - [17/Apr/2025:16:31:09 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:09,797] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22532, startOffset=0, estimatedUncompressedSize=5103498.0, md5=5b5e716708e70c43c54f133ffd25503b, chunkLength=141059, compressedSize=141072, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:09,797] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec, size=141072 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:09 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec. It took 210 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:10,012] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec, size=141072, timeInMillis=215, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,012] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:10,012] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,039] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec fileRegistrationPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 75] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,042] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:10,075] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7x_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_74.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,102] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23091, startOffset=0, estimatedUncompressedSize=5230111.5, md5=237109d9e6ed858a0a2afb53f4aa8078, chunkLength=144577, compressedSize=144592, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:10,102] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec, size=144592 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec. It took 218 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:10,325] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec, size=144592, timeInMillis=223, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,325] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:10,325] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,339] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec fileRegistrationPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 76] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,342] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:10,393] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22700, startOffset=0, estimatedUncompressedSize=5141550.0, md5=fe65dc62c29cf6812582357bd9ac64d8, chunkLength=141867, compressedSize=141872, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:10,395] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec, size=141872 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec
benchi-kafka-connect  | [2025-04-17 16:31:10,398] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_75.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec. It took 165 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:10,563] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec, size=141872, timeInMillis=168, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,563] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:10,563] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,615] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_76.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,643] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec fileRegistrationPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 77] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,645] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:10,704] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23789, startOffset=0, estimatedUncompressedSize=5388208.5, md5=9a82e2c8ac88add7f2af3c130641a1a5, chunkLength=148775, compressedSize=148784, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:10,704] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec, size=148784 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:10 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec. It took 195 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:10,902] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec, size=148784, timeInMillis=198, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,903] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:10,903] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:10,943] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec fileRegistrationPath=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 78] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:10,946] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:10,991] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_77.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,005] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22712, startOffset=0, estimatedUncompressedSize=5144268.0, md5=166b745c7adef2dfd4dcc7757d734c5c, chunkLength=142041, compressedSize=142048, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:11,005] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec, size=142048 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec. It took 180 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:11,189] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec, size=142048, timeInMillis=184, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,190] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:11,190] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,243] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec fileRegistrationPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 79] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,246] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:11,257] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7y_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_78.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,302] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22594, startOffset=0, estimatedUncompressedSize=5117541.0, md5=6047d84f4b8d67c4dab608ed3df2477d, chunkLength=141469, compressedSize=141472, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:11,302] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec, size=141472 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec
benchi-kafka-connect  | [2025-04-17 16:31:11,489] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec, size=141472, timeInMillis=187, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,489] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:11,489] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:11,542] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec fileRegistrationPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 80] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,545] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:11,564] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_79.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,597] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22969, startOffset=0, estimatedUncompressedSize=5202478.5, md5=29cbf26d811c672b49a13f6eaebdf17c, chunkLength=143822, compressedSize=143824, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:11,597] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec, size=143824 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec. It took 210 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:11,811] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec, size=143824, timeInMillis=214, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,811] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:11,811] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,846] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec fileRegistrationPath=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 81] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:11,849] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:11,870] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_80.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:11,910] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23131, startOffset=0, estimatedUncompressedSize=5239171.5, md5=adf26da014a4602fc42a664905116274, chunkLength=144749, compressedSize=144752, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:11,911] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec, size=144752 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:11 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec. It took 136 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:12,051] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec, size=144752, timeInMillis=140, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,052] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:12,052] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,124] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf7z_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_81.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,146] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec fileRegistrationPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 82] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,149] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:12,207] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22793, startOffset=0, estimatedUncompressedSize=5162614.5, md5=d5734940a1e40587c34e0508c216bbae, chunkLength=142521, compressedSize=142528, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:12,207] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec, size=142528 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec. It took 163 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:12,374] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec, size=142528, timeInMillis=167, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,374] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:12,374] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,446] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec fileRegistrationPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 83] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,448] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_82.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,449] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:12,504] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22390, startOffset=0, estimatedUncompressedSize=5071335.0, md5=6e0837dc52c73a39dfce9eeedc3a1478, chunkLength=140202, compressedSize=140208, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:12,505] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec, size=140208 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec. It took 187 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:12,695] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec, size=140208, timeInMillis=190, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,695] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:12,695] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,745] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec fileRegistrationPath=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 84] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:12,748] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:12,757] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_83.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:12,798] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22750, startOffset=0, estimatedUncompressedSize=5152875.0, md5=59f01a4b12c9614ac553cdbe190f9792, chunkLength=142266, compressedSize=142272, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:12,798] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec, size=142272 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec
benchi-kafka-connect  | [2025-04-17 16:31:12,985] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec, size=142272, timeInMillis=187, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:12 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:12,985] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:12,986] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,047] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec fileRegistrationPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 85] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,050] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:13,058] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf80_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_84.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,113] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23259, startOffset=0, estimatedUncompressedSize=5268163.5, md5=252ebe2ab546c38105f60c0e71a13b31, chunkLength=145616, compressedSize=145632, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:13,114] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec, size=145632 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec. It took 213 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:13,330] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec, size=145632, timeInMillis=216, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,331] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:13,331] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,348] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec fileRegistrationPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 86] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,351] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:13,400] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_85.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,409] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23042, startOffset=0, estimatedUncompressedSize=5219013.0, md5=79b9b71963afa56ac04a2f728602f487, chunkLength=143859, compressedSize=143872, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:13,409] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec, size=143872 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec
benchi-kafka-connect  | [2025-04-17 16:31:13,625] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec, size=143872, timeInMillis=216, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec. It took 212 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:13,625] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:13,625] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,647] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec fileRegistrationPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 87] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,650] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:13,695] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_86.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,707] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23239, startOffset=0, estimatedUncompressedSize=5263633.5, md5=3da75b78c833108f0d6b44ee05de121d, chunkLength=145311, compressedSize=145312, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:13,707] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec, size=145312 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:13 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec. It took 198 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:13,909] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec, size=145312, timeInMillis=202, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,909] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:13,909] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:13,947] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec fileRegistrationPath=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 88] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:13,949] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:13,961] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_87.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,001] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22532, startOffset=0, estimatedUncompressedSize=5103498.0, md5=9d145a6fd4847e3f7042a5fb75ae426b, chunkLength=141211, compressedSize=141216, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:14,001] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec, size=141216 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec
benchi-kafka-connect  | [2025-04-17 16:31:14,178] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec, size=141216, timeInMillis=177, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec. It took 172 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:14,178] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:14,178] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,231] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf81_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_88.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,250] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec fileRegistrationPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 89] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:14,253] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:14,313] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23514, startOffset=0, estimatedUncompressedSize=5325921.0, md5=56c991aac17bf917ef614d39c12feaf8, chunkLength=147145, compressedSize=147152, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:14,314] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec, size=147152 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec
benchi-kafka-connect  | [2025-04-17 16:31:14,441] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec, size=147152, timeInMillis=127, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec. It took 123 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:14,441] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:14,442] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,503] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_89.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,550] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec fileRegistrationPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 90] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:14,553] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:14,612] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22889, startOffset=0, estimatedUncompressedSize=5184358.5, md5=8894f4fbad316efb0c9fbfdf62f4c135, chunkLength=143361, compressedSize=143376, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:14,613] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec, size=143376 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec
benchi-kafka-connect  | [2025-04-17 16:31:14,798] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec, size=143376, timeInMillis=185, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:14,799] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:14,799] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,850] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec fileRegistrationPath=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 91] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:14,853] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:14,869] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_90.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:14,907] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22645, startOffset=0, estimatedUncompressedSize=5129092.5, md5=4a5341832f34b92cd8d0969510e4e8da, chunkLength=141809, compressedSize=141824, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:14,907] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec, size=141824 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:14 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec
benchi-kafka-connect  | [2025-04-17 16:31:15,007] INFO 172.25.0.3 - - [17/Apr/2025:16:31:15 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec. It took 220 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:15,132] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec, size=141824, timeInMillis=225, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:15,132] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:15,133] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,200] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf82_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_91.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,251] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec fileRegistrationPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 92] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:15,254] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:15,323] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28629, startOffset=0, estimatedUncompressedSize=6484468.5, md5=bad9c1ba25b5e30a6d6e4df2059c817e, chunkLength=178791, compressedSize=178800, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:15,323] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec, size=178800 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec
benchi-kafka-connect  | [2025-04-17 16:31:15,550] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec fileRegistrationPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 1, completed tasks = 92] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:15,554] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec. It took 235 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:15,561] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec, size=178800, timeInMillis=238, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:15,561] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:15,561] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,603] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22622, startOffset=0, estimatedUncompressedSize=5123883.0, md5=fd6fee850a9e06be6ce873f8f94ec4f5, chunkLength=141607, compressedSize=141616, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:15,604] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec, size=141616 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec
benchi-kafka-connect  | [2025-04-17 16:31:15,609] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_92.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,816] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec, size=141616, timeInMillis=212, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec. It took 209 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:15,816] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:15,816] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,854] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec fileRegistrationPath=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 94] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:15,857] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:15,872] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_93.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:15,925] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23305, startOffset=0, estimatedUncompressedSize=5278582.5, md5=4c5725004a88f80c8deb96ad47c88ac2, chunkLength=145766, compressedSize=145776, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:15,925] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec, size=145776 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:15 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec
benchi-kafka-connect  | [2025-04-17 16:31:16,153] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec fileRegistrationPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 1, completed tasks = 94] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,156] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec. It took 241 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:16,170] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec, size=145776, timeInMillis=245, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,170] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:16,170] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:16,214] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22431, startOffset=0, estimatedUncompressedSize=5080621.5, md5=76a01dc5a77147e18f577f20bc2e88b9, chunkLength=140482, compressedSize=140496, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:16,215] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec, size=140496 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec
benchi-kafka-connect  | [2025-04-17 16:31:16,224] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf83_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_94.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec. It took 203 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:16,420] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec, size=140496, timeInMillis=205, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,421] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:16,421] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:16,453] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec fileRegistrationPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 96] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,456] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:16,500] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_95.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:16,507] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22601, startOffset=0, estimatedUncompressedSize=5119126.5, md5=8ce2cce84db09108f0377168432c81ad, chunkLength=141540, compressedSize=141552, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:16,509] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec, size=141552 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec. It took 214 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:16,726] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec, size=141552, timeInMillis=217, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,726] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:16,726] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:16,752] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec fileRegistrationPath=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 97] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:16,755] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:16,805] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_96.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:16,808] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23827, startOffset=0, estimatedUncompressedSize=5396815.5, md5=3967ad3e1f812fa464fcfe7e0c83de1b, chunkLength=148925, compressedSize=148928, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:16,808] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec, size=148928 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:16 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec. It took 237 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:17,049] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec, size=148928, timeInMillis=241, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:17,049] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:17,049] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,055] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec fileRegistrationPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 98] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:17,058] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:17,097] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf84_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_97.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,130] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=25158, startOffset=0, estimatedUncompressedSize=5698287.0, md5=18c5c08d8ece57bfb54e89c9b087d450, chunkLength=157186, compressedSize=157200, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:17,130] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec, size=157200 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:17,309] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec, size=157200, timeInMillis=179, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:17,309] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:17,309] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,362] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_98.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,457] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec fileRegistrationPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 99] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:17,459] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:17,536] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29464, startOffset=0, estimatedUncompressedSize=6673596.0, md5=0c19831e4b7aef84e4f2a603e48a9159, chunkLength=183867, compressedSize=183872, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:17,536] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec, size=183872 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec
benchi-kafka-connect  | [2025-04-17 16:31:17,738] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec, size=183872, timeInMillis=202, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec. It took 198 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:17,738] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:17,738] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,755] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec fileRegistrationPath=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 100] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:17,760] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:17,805] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_99.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:17,817] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22623, startOffset=0, estimatedUncompressedSize=5124109.5, md5=a0882c720d92ea8b8b83957a0961d894, chunkLength=141611, compressedSize=141616, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:17,817] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec, size=141616 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:17 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec
benchi-kafka-connect  | [2025-04-17 16:31:17,879] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:17,929] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:2451959 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:31:17,929] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 50 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec. It took 210 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:18,030] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec, size=141616, timeInMillis=213, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,030] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:18,031] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,089] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf85_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_100.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,156] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec fileRegistrationPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 101] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,159] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:18,222] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=26130, startOffset=0, estimatedUncompressedSize=5918445.0, md5=cae52da00f331d340833aff879eaba48, chunkLength=163341, compressedSize=163344, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:18,222] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec, size=163344 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec. It took 210 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:18,435] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec, size=163344, timeInMillis=213, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,435] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:18,435] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,518] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_101.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,561] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec fileRegistrationPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 102] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,563] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:18,631] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28910, startOffset=0, estimatedUncompressedSize=6548115.0, md5=891f86ff79315539dfc8d087c654de08, chunkLength=180453, compressedSize=180464, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:18,631] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec, size=180464 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec. It took 191 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:18,826] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec, size=180464, timeInMillis=195, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,827] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:18,828] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,865] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec fileRegistrationPath=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 103] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:18,868] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:18,885] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_102.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:18,921] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23016, startOffset=0, estimatedUncompressedSize=5213124.0, md5=cb2631652ecaa6bb55d92d9d4449098a, chunkLength=143767, compressedSize=143776, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:18,922] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec, size=143776 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:18 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec. It took 215 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:19,141] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec, size=143776, timeInMillis=218, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,141] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:19,141] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,170] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec fileRegistrationPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 104] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,174] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:19,205] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf86_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_103.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,223] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23160, startOffset=0, estimatedUncompressedSize=5245740.0, md5=3da8396cdcab84e2a36fe4f06d323bf4, chunkLength=144905, compressedSize=144912, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:19,223] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec, size=144912 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec. It took 206 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:19,433] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec, size=144912, timeInMillis=209, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,433] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:19,433] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,504] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_104.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,574] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec fileRegistrationPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 105] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,577] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:19,648] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=28691, startOffset=0, estimatedUncompressedSize=6498511.5, md5=fe5821c57064ef863c5bdadfc4fd2ea3, chunkLength=179078, compressedSize=179088, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:19,649] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec, size=179088 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec. It took 174 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:19,826] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec, size=179088, timeInMillis=177, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,827] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:19,827] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,874] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec fileRegistrationPath=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 106] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:19,877] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:19,880] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_105.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:19,935] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22705, startOffset=0, estimatedUncompressedSize=5142682.5, md5=2fc53613c2a14bd0e7e1138113afc5bc, chunkLength=142074, compressedSize=142080, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:19,935] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec, size=142080 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:19 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec. It took 193 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:20,132] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec, size=142080, timeInMillis=197, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,132] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:20,132] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,174] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec fileRegistrationPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 107] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,176] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:20,184] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf87_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_106.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,230] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22516, startOffset=0, estimatedUncompressedSize=5099874.0, md5=feb31e1053b99e81ab1bd232308bfe5d, chunkLength=141027, compressedSize=141040, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:20,230] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec, size=141040 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec. It took 166 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:20,400] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec, size=141040, timeInMillis=170, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,400] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:20,400] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,404] INFO 172.25.0.3 - - [17/Apr/2025:16:31:20 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:20,457] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_107.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,473] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec fileRegistrationPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 108] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,476] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:20,528] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23016, startOffset=0, estimatedUncompressedSize=5213124.0, md5=12b4be54fd5b13de1c6948830dd54586, chunkLength=143988, compressedSize=144000, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:20,528] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec, size=144000 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec. It took 194 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:20,725] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec, size=144000, timeInMillis=197, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,726] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:20,726] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,776] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec fileRegistrationPath=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 109] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:20,780] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:20,801] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_108.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:20,842] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23515, startOffset=0, estimatedUncompressedSize=5326147.5, md5=7cbe848e48a312c923ff39c7d58ac61c, chunkLength=147075, compressedSize=147088, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:20,842] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec, size=147088 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:20 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec. It took 203 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:21,049] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec, size=147088, timeInMillis=207, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,049] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:21,049] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,076] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec fileRegistrationPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 110] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,079] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:21,119] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf88_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_109.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,135] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22491, startOffset=0, estimatedUncompressedSize=5094211.5, md5=cb2d16cd088d2910a57898161622366f, chunkLength=140913, compressedSize=140928, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:21,136] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec, size=140928 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec. It took 171 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:21,310] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec, size=140928, timeInMillis=174, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,311] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:21,311] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,358] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_110.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,375] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec fileRegistrationPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 111] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,379] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:21,432] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22786, startOffset=0, estimatedUncompressedSize=5161029.0, md5=b80e4726f9fa35f5660ad42d34c50a3f, chunkLength=142414, compressedSize=142416, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:21,433] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec, size=142416 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec. It took 186 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:21,622] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec, size=142416, timeInMillis=189, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,623] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:21,623] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,677] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec fileRegistrationPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 112] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,680] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:21,681] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_111.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,731] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23214, startOffset=0, estimatedUncompressedSize=5257971.0, md5=c07ba76c5e45db915a32e0ca473ebbfd, chunkLength=145129, compressedSize=145136, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:21,732] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec, size=145136 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:21 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec. It took 216 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:21,952] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec, size=145136, timeInMillis=220, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,953] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:21,953] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:21,977] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec fileRegistrationPath=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 113] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:21,981] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:22,036] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_112.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,049] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23310, startOffset=0, estimatedUncompressedSize=5279715.0, md5=2a03e11aedc5e82a11fb87274e9050c2, chunkLength=145848, compressedSize=145856, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:22,049] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec, size=145856 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec. It took 170 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:22,223] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec, size=145856, timeInMillis=174, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,223] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:22,223] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,279] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec fileRegistrationPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 114] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,281] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:22,295] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf89_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_113.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,337] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22280, startOffset=0, estimatedUncompressedSize=5046420.0, md5=65e9d5336f6c13a843376c0fabb798df, chunkLength=139589, compressedSize=139600, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:22,337] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec, size=139600 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec. It took 182 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:22,523] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec, size=139600, timeInMillis=186, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,523] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:22,523] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,578] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec fileRegistrationPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 115] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,580] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:22,595] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_114.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,634] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22769, startOffset=0, estimatedUncompressedSize=5157178.5, md5=2127f4cee8ff53d9032138bac492da83, chunkLength=142421, compressedSize=142432, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:22,634] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec, size=142432 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec. It took 177 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:22,815] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec, size=142432, timeInMillis=181, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,815] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:22,816] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,878] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec fileRegistrationPath=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 116] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:22,881] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:22,887] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_115.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:22,934] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22556, startOffset=0, estimatedUncompressedSize=5108934.0, md5=2cadce93a5fdf5732614faab76e82471, chunkLength=141153, compressedSize=141168, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:22,935] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec, size=141168 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:22 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec. It took 172 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:23,110] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec, size=141168, timeInMillis=175, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,110] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:23,110] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,165] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8a_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_116.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,181] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec fileRegistrationPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 117] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,184] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:23,248] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23172, startOffset=0, estimatedUncompressedSize=5248458.0, md5=af710ca6716a44613132c4e5c8ee83c8, chunkLength=145007, compressedSize=145008, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:23,249] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec, size=145008 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec. It took 189 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:23,442] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec, size=145008, timeInMillis=193, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,442] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:23,442] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,481] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec fileRegistrationPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 0, completed tasks = 118] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,483] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:23,515] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_117.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,539] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22252, startOffset=0, estimatedUncompressedSize=5040078.0, md5=1bc64b9a11593ac90630029de28e949c, chunkLength=139257, compressedSize=139264, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:23,540] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec, size=139264 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec
benchi-kafka-connect  | [2025-04-17 16:31:23,709] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec, size=139264, timeInMillis=169, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,710] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec. It took 166 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:23,710] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,777] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_118.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:23,780] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec fileRegistrationPath=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 119] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:23,783] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:23,838] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22351, startOffset=0, estimatedUncompressedSize=5062501.5, md5=06496ab6373af2815e4aa7a43a2a214f, chunkLength=140095, compressedSize=140096, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:23,838] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec, size=140096 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:23 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:24,025] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec, size=140096, timeInMillis=187, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,025] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:24,025] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,077] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8b_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_119.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,080] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec fileRegistrationPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 120] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,084] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:24,135] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22742, startOffset=0, estimatedUncompressedSize=5151063.0, md5=5f0334ebe74ddf663c0201447445eb82, chunkLength=142370, compressedSize=142384, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:24,135] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec, size=142384 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:24,315] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec, size=142384, timeInMillis=180, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,315] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:24,315] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,370] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_120.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,383] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec fileRegistrationPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 121] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,385] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:24,450] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23278, startOffset=0, estimatedUncompressedSize=5272467.0, md5=8cf9ad04bb8d50ea7356007e27a411f6, chunkLength=145508, compressedSize=145520, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:24,450] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec, size=145520 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:24,636] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec, size=145520, timeInMillis=186, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,638] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:24,638] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,683] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec fileRegistrationPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 122] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,686] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:24,690] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_121.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,743] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22886, startOffset=0, estimatedUncompressedSize=5183679.0, md5=aacbc77a94d100fc895b70298327a112, chunkLength=143241, compressedSize=143248, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:24,743] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec, size=143248 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:24 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec. It took 176 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:24,923] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec, size=143248, timeInMillis=180, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,923] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:24,924] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:24,984] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec fileRegistrationPath=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 123] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:24,987] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:24,992] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_122.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,044] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22692, startOffset=0, estimatedUncompressedSize=5139738.0, md5=46d4baf698cb58fb5fa5a6a7dc0bee13, chunkLength=142093, compressedSize=142096, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:25,044] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec, size=142096 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec
benchi-kafka-connect  | [2025-04-17 16:31:25,227] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec, size=142096, timeInMillis=183, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec. It took 178 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:25,227] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:25,227] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,284] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec fileRegistrationPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 124] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:25,287] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:25,314] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8c_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_123.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,337] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22890, startOffset=0, estimatedUncompressedSize=5184585.0, md5=3e1a6d2890679c2ceb8e93d683a5fedc, chunkLength=143405, compressedSize=143408, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:25,337] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec, size=143408 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec. It took 184 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:25,525] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec, size=143408, timeInMillis=188, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:25,526] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:25,526] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,585] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_124.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,587] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec fileRegistrationPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 125] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:25,589] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:25,643] INFO 172.25.0.3 - - [17/Apr/2025:16:31:25 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:25,657] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23596, startOffset=0, estimatedUncompressedSize=5344494.0, md5=dd0bd80ee0ebbfaefebf6934951164ae, chunkLength=147719, compressedSize=147728, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:25,657] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec, size=147728 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec. It took 172 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:25,832] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec, size=147728, timeInMillis=175, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:25,832] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:25,832] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,887] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec fileRegistrationPath=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 126] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:25,890] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:25,902] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_125.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:25,950] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22915, startOffset=0, estimatedUncompressedSize=5190247.5, md5=484ee9fc5b156548b82f082bd14f7c08, chunkLength=143449, compressedSize=143456, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:25,951] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec, size=143456 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:25 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec. It took 218 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:26,172] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec, size=143456, timeInMillis=221, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,173] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:26,173] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,187] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec fileRegistrationPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 127] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,190] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:26,223] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8d_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_126.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,244] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22223, startOffset=0, estimatedUncompressedSize=5033509.5, md5=3c15ff20aa68abd8d9aaffde6f4f5208, chunkLength=139132, compressedSize=139136, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:26,245] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec, size=139136 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec. It took 200 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:26,451] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec, size=139136, timeInMillis=206, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,451] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:26,451] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,487] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec fileRegistrationPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 128] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,490] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:26,527] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_127.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,539] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22432, startOffset=0, estimatedUncompressedSize=5080848.0, md5=962827b66bea229f549447beb397ed00, chunkLength=140513, compressedSize=140528, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:26,540] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec, size=140528 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec. It took 204 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:26,747] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec, size=140528, timeInMillis=207, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,747] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:26,747] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,789] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec fileRegistrationPath=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 129] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:26,791] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:26,824] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_128.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:26,857] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23494, startOffset=0, estimatedUncompressedSize=5321391.0, md5=40f4595a21d0fe617cf225578038d3fc, chunkLength=146953, compressedSize=146960, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:26,857] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec, size=146960 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:26 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec
benchi-kafka-connect  | [2025-04-17 16:31:27,030] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec, size=146960, timeInMillis=173, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,030] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:27,031] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec. It took 169 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:27,081] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8e_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_129.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:27,088] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec fileRegistrationPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 130] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,092] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:27,148] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23024, startOffset=0, estimatedUncompressedSize=5214936.0, md5=cd9a8fde6be47ed60cde387b11199149, chunkLength=143994, compressedSize=144000, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:27,149] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec, size=144000 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec. It took 222 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:27,374] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec, size=144000, timeInMillis=225, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,374] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:27,374] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:27,389] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec fileRegistrationPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 0, completed tasks = 131] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,392] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:27,426] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_130.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:27,446] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23016, startOffset=0, estimatedUncompressedSize=5213124.0, md5=35a34ea3165a2e6a6c972a0cd85c63e7, chunkLength=144240, compressedSize=144256, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:27,447] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec, size=144256 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec. It took 175 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:27,625] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec, size=144256, timeInMillis=178, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,626] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:27,626] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:27,682] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_131.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:27,688] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec fileRegistrationPath=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 132] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,691] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:27,743] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23516, startOffset=0, estimatedUncompressedSize=5326374.0, md5=fab93943fc30041b6079118f8fa3e786, chunkLength=147096, compressedSize=147104, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:27,744] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec, size=147104 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec
benchi-kafka-connect  | [2025-04-17 16:31:27,879] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:27,931] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:3228074 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:31:27,932] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 53 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | Apr 17, 2025 4:31:27 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec. It took 190 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:27,937] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec, size=147104, timeInMillis=193, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:27,938] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:27,938] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,008] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8f_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_132.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,089] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec fileRegistrationPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 133] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,092] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:28,150] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=26830, startOffset=0, estimatedUncompressedSize=6076995.0, md5=6c1839203c38813ad0294ac7b3699adb, chunkLength=167513, compressedSize=167520, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:28,150] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec, size=167520 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec. It took 153 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:28,306] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec, size=167520, timeInMillis=156, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,306] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:28,307] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,374] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_133.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,392] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec fileRegistrationPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 134] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,395] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:28,462] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23595, startOffset=0, estimatedUncompressedSize=5344267.5, md5=483f999a83979c0f339c73146e70cc65, chunkLength=147625, compressedSize=147632, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:28,462] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec, size=147632 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec. It took 186 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:28,651] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec, size=147632, timeInMillis=189, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,651] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:28,651] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,691] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec fileRegistrationPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 135] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,695] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:28,702] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_134.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,751] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23055, startOffset=0, estimatedUncompressedSize=5221957.5, md5=8b831a1db004dab9cf3f7e0a633b73f4, chunkLength=144245, compressedSize=144256, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:28,751] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec, size=144256 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:28 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec. It took 198 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:28,953] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec, size=144256, timeInMillis=201, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,954] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:28,954] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:28,992] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec fileRegistrationPath=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 136] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:28,995] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:29,013] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_135.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,049] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22756, startOffset=0, estimatedUncompressedSize=5154234.0, md5=629db0a245e1705b237fe371d02c7ce0, chunkLength=142438, compressedSize=142448, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:29,049] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec, size=142448 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec
benchi-kafka-connect  | [2025-04-17 16:31:29,291] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec fileRegistrationPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 1, completed tasks = 136] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:29,295] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec. It took 245 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:29,297] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec, size=142448, timeInMillis=248, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:29,297] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:29,298] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,342] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22352, startOffset=0, estimatedUncompressedSize=5062728.0, md5=bef55ddd597fe33d8566b18d8924cf84, chunkLength=140027, compressedSize=140032, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:29,342] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec, size=140032 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec
benchi-kafka-connect  | [2025-04-17 16:31:29,371] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8g_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_136.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec. It took 182 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:29,527] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec, size=140032, timeInMillis=185, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:29,527] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:29,528] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,594] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec fileRegistrationPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 138] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:29,595] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_137.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,597] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:29,663] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23494, startOffset=0, estimatedUncompressedSize=5321391.0, md5=41bce05ab221fc1a1a1be6f921476b71, chunkLength=147042, compressedSize=147056, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:29,663] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec, size=147056 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:29 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec. It took 180 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:29,846] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec, size=147056, timeInMillis=183, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:29,846] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:29,846] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,905] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_138.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:29,996] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec fileRegistrationPath=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 0, completed tasks = 139] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,001] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:30,090] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=30017, startOffset=0, estimatedUncompressedSize=6798850.5, md5=966b9cd0c728c56d6fd59ed03a1dc027, chunkLength=187269, compressedSize=187280, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:30,091] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec, size=187280 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec. It took 195 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:30,291] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec, size=187280, timeInMillis=200, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,291] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:30,291] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,295] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec fileRegistrationPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 0, completed tasks = 140] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,298] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:30,344] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8h_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_139.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,357] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22581, startOffset=0, estimatedUncompressedSize=5114596.5, md5=93688f1fc2990fcdcb504ef300c07896, chunkLength=141351, compressedSize=141360, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:30,357] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec, size=141360 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec. It took 139 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:30,499] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec, size=141360, timeInMillis=142, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,500] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:30,500] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,580] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_140.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,595] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec fileRegistrationPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 141] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,597] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:30,652] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22980, startOffset=0, estimatedUncompressedSize=5204970.0, md5=c8ed454aa83d4ac08b8e157eea1f4355, chunkLength=143837, compressedSize=143840, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:30,652] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec, size=143840 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec
benchi-kafka-connect  | [2025-04-17 16:31:30,821] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec, size=143840, timeInMillis=169, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec. It took 166 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:30,821] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:30,821] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,892] INFO 172.25.0.3 - - [17/Apr/2025:16:31:30 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:30,895] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec fileRegistrationPath=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 142] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:30,897] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_141.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:30,898] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:30,948] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23016, startOffset=0, estimatedUncompressedSize=5213124.0, md5=760cf4579ed7f8c23bdb405ec6aa8d1d, chunkLength=144002, compressedSize=144016, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:30,948] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec, size=144016 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:30 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec. It took 201 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:31,152] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec, size=144016, timeInMillis=204, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,152] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:31,152] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,197] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec fileRegistrationPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 143] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,199] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:31,202] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8i_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_142.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,266] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23516, startOffset=0, estimatedUncompressedSize=5326374.0, md5=73ec882e4b52bf31ff8cf88ded3755be, chunkLength=147343, compressedSize=147344, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:31,266] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec, size=147344 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec. It took 166 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:31,436] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec, size=147344, timeInMillis=170, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,436] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:31,436] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,484] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_143.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,497] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec fileRegistrationPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 144] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,500] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:31,556] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22955, startOffset=0, estimatedUncompressedSize=5199307.5, md5=b6468c186d0aa7e08393e9e993677ecd, chunkLength=143646, compressedSize=143648, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:31,557] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec, size=143648 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec. It took 176 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:31,737] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec, size=143648, timeInMillis=179, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,737] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:31,737] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,787] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_144.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:31,797] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec fileRegistrationPath=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 145] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:31,800] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:31,862] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23077, startOffset=0, estimatedUncompressedSize=5226940.5, md5=bab9c8f2192c8d4212e6de6cdc76496c, chunkLength=144354, compressedSize=144368, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:31,862] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec, size=144368 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:31 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec. It took 205 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:32,072] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec, size=144368, timeInMillis=210, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,073] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:32,073] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,096] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec fileRegistrationPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 146] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,099] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:32,141] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8j_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_145.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,150] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22991, startOffset=0, estimatedUncompressedSize=5207461.5, md5=4836d0961aaf5aa0e1bdfe8cf34c33a7, chunkLength=143945, compressedSize=143952, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:32,150] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec, size=143952 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:32,334] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec, size=143952, timeInMillis=184, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,335] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:32,335] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,401] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec fileRegistrationPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 147] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,404] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:32,411] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_146.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,474] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23541, startOffset=0, estimatedUncompressedSize=5332036.5, md5=231b2a3d784b63a99329461f0e0fdfd7, chunkLength=147443, compressedSize=147456, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:32,474] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec, size=147456 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec. It took 182 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:32,661] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec, size=147456, timeInMillis=187, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,661] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:32,661] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,699] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec fileRegistrationPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 148] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,702] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:32,730] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_147.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,760] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23016, startOffset=0, estimatedUncompressedSize=5213124.0, md5=fa94f2cba0cb0a5a5f9b7ab390f938ba, chunkLength=143874, compressedSize=143888, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:32,760] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec, size=143888 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:32 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec. It took 177 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:32,941] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec, size=143888, timeInMillis=181, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:32,942] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:32,942] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,992] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_148.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:32,999] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec fileRegistrationPath=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 149] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:33,002] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:33,056] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23063, startOffset=0, estimatedUncompressedSize=5223769.5, md5=14ac3abfed3d79a99618e370cd63a48f, chunkLength=144340, compressedSize=144352, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:33,057] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec, size=144352 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec
benchi-kafka-connect  | [2025-04-17 16:31:33,241] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec, size=144352, timeInMillis=184, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec. It took 181 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:33,242] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:33,242] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,299] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec fileRegistrationPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 150] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:33,302] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:33,303] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8k_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_149.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,353] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23151, startOffset=0, estimatedUncompressedSize=5243701.5, md5=88a659358e6a00b21adac60d93c09e7e, chunkLength=144854, compressedSize=144864, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:33,353] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec, size=144864 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec
benchi-kafka-connect  | [2025-04-17 16:31:33,546] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec, size=144864, timeInMillis=193, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec. It took 189 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:33,546] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:33,546] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,601] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec fileRegistrationPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 151] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:33,604] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:33,624] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_150.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,665] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23342, startOffset=0, estimatedUncompressedSize=5286963.0, md5=f3324f8c06084223af280df7bf4b1afa, chunkLength=146106, compressedSize=146112, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:33,666] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec, size=146112 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec
benchi-kafka-connect  | [2025-04-17 16:31:33,802] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec, size=146112, timeInMillis=136, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec. It took 132 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:33,802] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:33,802] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,868] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_151.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:33,902] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec fileRegistrationPath=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 152] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:33,904] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:33,962] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22538, startOffset=0, estimatedUncompressedSize=5104857.0, md5=21d381eabfdfb5f5f25fdbd417c94f4e, chunkLength=140859, compressedSize=140864, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:33,962] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec, size=140864 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:33 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec
benchi-kafka-connect  | [2025-04-17 16:31:34,155] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec, size=140864, timeInMillis=193, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec. It took 189 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:34,155] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:34,155] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,202] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec fileRegistrationPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 153] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:34,204] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:34,234] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8l_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_152.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,258] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22513, startOffset=0, estimatedUncompressedSize=5099194.5, md5=02d6f070260f56be5a676c04b59893b5, chunkLength=140727, compressedSize=140736, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:34,259] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec, size=140736 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec. It took 169 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:34,431] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec, size=140736, timeInMillis=172, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:34,431] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:34,431] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,477] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_153.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,501] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec fileRegistrationPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 154] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:34,505] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:34,555] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22997, startOffset=0, estimatedUncompressedSize=5208820.5, md5=968b555de4839cc86ed3b5be91c0234a, chunkLength=143934, compressedSize=143936, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:34,556] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec, size=143936 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec
benchi-kafka-connect  | [2025-04-17 16:31:34,747] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec, size=143936, timeInMillis=191, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:34,747] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:34,747] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,804] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec fileRegistrationPath=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 155] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:34,807] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:34,825] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_154.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:34,868] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23457, startOffset=0, estimatedUncompressedSize=5313010.5, md5=1aa7f8e0b24ae4cee5d12cc1c17989d7, chunkLength=146755, compressedSize=146768, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:34,868] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec, size=146768 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:34 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec. It took 192 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:35,065] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec, size=146768, timeInMillis=197, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,065] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:35,066] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,104] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec fileRegistrationPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 156] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,107] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:35,153] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8m_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_155.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,163] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22281, startOffset=0, estimatedUncompressedSize=5046646.5, md5=953556a12da5660d58eb96c2fbe1cca5, chunkLength=139601, compressedSize=139616, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:35,164] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec, size=139616 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec. It took 187 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:35,355] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec, size=139616, timeInMillis=191, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,356] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:35,356] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,403] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec fileRegistrationPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 157] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,407] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:35,431] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_156.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,477] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22793, startOffset=0, estimatedUncompressedSize=5162614.5, md5=fc7108e33930f898add37244075301c0, chunkLength=142672, compressedSize=142688, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:35,477] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec, size=142688 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec. It took 170 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:35,650] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec, size=142688, timeInMillis=173, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,651] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:35,651] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,704] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_157.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:35,805] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec fileRegistrationPath=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 158] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:35,808] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:35,877] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=29718, startOffset=0, estimatedUncompressedSize=6731127.0, md5=c2ed1b6c934fe2f9069bc42851f1605a, chunkLength=185423, compressedSize=185424, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:35,877] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec, size=185424 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:35 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec. It took 212 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:36,092] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec, size=185424, timeInMillis=215, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,093] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:36,093] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,103] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec fileRegistrationPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 159] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,107] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:36,153] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8n_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_158.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,157] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22753, startOffset=0, estimatedUncompressedSize=5153554.5, md5=015c36d8ff572da2b23a619a50c1637a, chunkLength=142438, compressedSize=142448, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:36,157] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec, size=142448 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec
benchi-kafka-connect  | [2025-04-17 16:31:36,315] INFO 172.25.0.3 - - [17/Apr/2025:16:31:36 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec. It took 200 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:36,361] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec, size=142448, timeInMillis=204, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,361] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:36,361] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,407] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec fileRegistrationPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 160] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,408] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_159.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,410] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:36,470] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=23234, startOffset=0, estimatedUncompressedSize=5262501.0, md5=4e97de87d6259686b25b966d8af318db, chunkLength=145487, compressedSize=145488, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:36,470] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec, size=145488 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec. It took 189 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:36,664] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec, size=145488, timeInMillis=194, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,664] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:36,664] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,707] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec fileRegistrationPath=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 161] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,710] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:36,740] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_160.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:36,767] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22658, startOffset=0, estimatedUncompressedSize=5132037.0, md5=3e224e9d165d0482f91ff4692b3f0fa2, chunkLength=141732, compressedSize=141744, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:36,767] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec, size=141744 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec
benchi-kafka-connect  | Apr 17, 2025 4:31:36 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec. It took 180 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:36,950] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec, size=141744, timeInMillis=183, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:36,951] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:36,951] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:37,007] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec fileRegistrationPath=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 0, queued tasks = 1, completed tasks = 162] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:37,011] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:37,021] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8o_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_161.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:37,065] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22742, startOffset=0, estimatedUncompressedSize=5151063.0, md5=2b0a8473610a30ad555a6d0028683478, chunkLength=142223, compressedSize=142224, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:37,065] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec, size=142224 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:37 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec
benchi-kafka-connect  | [2025-04-17 16:31:37,307] INFO [SF_INGEST] buildAndUpload task added for client=KC_CLIENT_snowflake_sink_1996731346_0, blob=uploadPath=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec fileRegistrationPath=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec, buildUploadWorkers stats=java.util.concurrent.ThreadPoolExecutor@3f456325[Running, pool size = 24, active threads = 1, queued tasks = 1, completed tasks = 162] (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:37,310] INFO Got brand-new compressor [.gz] (net.snowflake.ingest.internal.apache.hadoop.io.compress.CodecPool)
benchi-kafka-connect  | [2025-04-17 16:31:37,329] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec, size=142224, timeInMillis=263, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:37 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec. It took 261 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:37,330] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:37,330] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:37,359] INFO [SF_INGEST] Finish building chunk in blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec, table=BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952, rowCount=22516, startOffset=0, estimatedUncompressedSize=5099874.0, md5=a1cbcacba4e17a088b164305dd14677a, chunkLength=140822, compressedSize=140832, encrypt=true, bdecVersion=THREE (net.snowflake.ingest.streaming.internal.BlobBuilder)
benchi-kafka-connect  | [2025-04-17 16:31:37,359] INFO [SF_INGEST] Start uploading blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec, size=140832 (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | Apr 17, 2025 4:31:37 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Starting upload from stream (byte stream) to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec
benchi-kafka-connect  | [2025-04-17 16:31:37,384] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_162.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | Apr 17, 2025 4:31:37 PM net.snowflake.client.jdbc.cloud.storage.SnowflakeS3Client upload
benchi-kafka-connect  | INFO: Uploaded data from input stream to S3 location: 9r3d-s-ohsw4858/streaming_ingest/2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec. It took 183 ms with 0 retries
benchi-kafka-connect  | [2025-04-17 16:31:37,546] INFO [SF_INGEST] Finish uploading blob=2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec, size=140832, timeInMillis=187, etag=Optional.empty (net.snowflake.ingest.streaming.internal.FlushService)
benchi-kafka-connect  | [2025-04-17 16:31:37,546] INFO [SF_INGEST] Start registering blobs in client=KC_CLIENT_snowflake_sink_1996731346_0, totalBlobListSize=1, currentBlobListSize=1, idx=1 (net.snowflake.ingest.streaming.internal.RegisterService)
benchi-kafka-connect  | [2025-04-17 16:31:37,546] INFO [SF_INGEST] Register blob request preparing for blob=[2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec], clientName=KC_CLIENT_snowflake_sink_1996731346_0, clientKey=hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:37,604] INFO [SF_INGEST] Register blob request returned for blob=[2025/4/17/16/31/suvf8p_hWkNLasEQ8vE3grntToyBBRAvBB3GNqoz0SVUUMA1TV98CC_1016_59_163.bdec], client=KC_CLIENT_snowflake_sink_1996731346_0, executionCount=0 (net.snowflake.ingest.streaming.internal.SnowflakeStreamingIngestClientInternal)
benchi-kafka-connect  | [2025-04-17 16:31:37,880] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:37,913] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:3981118 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:31:37,913] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 33 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:41,415] INFO 172.25.0.3 - - [17/Apr/2025:16:31:41 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 3 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:46,524] INFO 172.25.0.3 - - [17/Apr/2025:16:31:46 +0000] "GET /connectors HTTP/1.1" 200 18 "-" "curl/7.61.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer)
benchi-kafka-connect  | [2025-04-17 16:31:47,914] INFO [SF_KAFKA_CONNECTOR] Precommit started for 1 partitions (com.snowflake.kafka.connector.SnowflakeSinkTask)
benchi-kafka-connect  | [2025-04-17 16:31:48,026] INFO [SF_KAFKA_CONNECTOR] Fetched offsetToken for channelName:BENCHI.PUBLIC.SNOWFLAKE_TEST_USERS_665962952.SNOWFLAKE.TEST.USERS_0, offset:3981118 (com.snowflake.kafka.connector.internal.streaming.DirectTopicPartitionChannel)
benchi-kafka-connect  | [2025-04-17 16:31:48,026] INFO [SF_KAFKA_CONNECTOR] Successfully called PRECOMMIT on all 1 partitions, safe to commit 1 partitions, executionTime: 112 ms (com.snowflake.kafka.connector.SnowflakeSinkTask)
[Kbenchi-kafka-connect exited with code 137
